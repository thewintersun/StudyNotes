#### Perceive Where to Focus: Learning Visibility-aware Part-level Features for Partial Person Re-identification

论文地址：https://arxiv.org/abs/1904.00537

作者: Yifan Sun, Qin Xu, Yali Li, Chi Zhang, Yikang Li, Shengjin Wang, Jian Sun

机构： 旷视

介绍文章：https://mp.weixin.qq.com/s/CF4vKVz5cEPIP_4RzqkJqw

介绍文章：https://mp.weixin.qq.com/s/d64bmtwagLZTmHnshcRvHw



围绕行人再识别，并针对实际情况下行人经常被遮挡、仅能被部分成像这一困难，旷视研究院提出一种==可见部件感知模型 VPM，其可通过自监督学习感知哪些部件可见或不可见，并在比较两幅图像时，聚焦在二者共同可见的部件上==，显著提高部分成像下的行人再识别准确率。

#### **导语**

近年来，行人再识别研究取得迅速进展，2018 年下，在公开数据集 Market-1501 上，SOTA 方法的一选准确率已达到 95% 甚至更高水平；与此同时，CV 产业界也开始发力，推动其场景落地。但是在实际 re-ID 系统中，一些极具挑战性的问题正等待克服，部分成像下的行人再识别（partial re-ID）即是其中之一。

在 partial re-ID 场景下，图像可能只包含行人的部分可见信息，例如腿部被遮挡、只有上半身被成像。此时，未经针对性设计的行人再识别方法通常会遭遇性能“滑铁卢”，无法再准确识别行人。

为此，旷视研究院联合清华大学，==提出一种可见性感知局部模型 VPM（Visibility-aware Part Model），通过自监督学习感知哪些部件可见/不可见（这种能力称之为“可见部件感知能力”），并在比较两幅图像时，聚焦在共同可见的部件上==，显著提高部分成像下的行人再识别准确率。

对于 partial re-ID，VPM 具有两方面的优势：

1）VPM 引入了部件特征，因此，与在传统全身的行人再识别（holistic re-ID）问题中一样，部件特征受益于细粒度信息，获得更好的鉴别能力；

2）由于具备可见部件感知能力，VPM 可估计出两张图像之间的共享区域，并在评估其相似性时聚焦在共享区域，这种做法符合人脑识别行人的思维习惯。

实验结果证明，VPM 可显著改善特征表达，在 re-ID、尤其是 partial re-ID 问题上取得了优异性能。

#### **从 PCB 说起** 

PCB（Part-based Convolutional Baseline） 一文其实提出两个方法——PCB 和 RPP（Refined Part Pooling），其中 PCB 是非常简单的部件学习 baseline，相关研究员已很熟悉。如图 1 所示，PCB 最大的特点是在卷积特征层进行均匀水平分割产生相应的部件特征。

后续一些方法把 PCB 作为 baseline，也取得了大幅提升，比如引入多粒度的均匀分割的 MGN。此外，旷视研究院还将此应用于大规模实际数据集，同样取得可观的提升。

​       ![1563883972466](C:\Users\j00496872\Desktop\Notes\raw_images\1563883972466.png)

​														图 1： PCB 网络结构示意

关于 PCB，解读很多，但是唯独没人注意到这样一个 insight：其实，PCB 采用的是抽象划分。它的抽象性在于，我们并不知道每一个 part 到底是什么。例如，图 1 part 1 可能对应了大部分人的“头部 + 1/2 个胸部”。这算什么 part ？如果非要命名，只能勉强称为“半头半胸”。

但是，只要这个部件对于大部分图像足够稳定，那么，深度模型就能够在学习过程中形成这样一个概念：“半头半胸”是一个部件。

简而言之，在 PCB 学习过程中，每个特征提取 branch 各自“记住”所负责部件的样子，尽管并未显式地定义各个部件是什么。照这么看，RPP 也就不再费解了（很多人对 RPP 训练时无需 part 标签，却能够识别各个 part 表示不能理解）—— 既然 branch 知道如何处理部件，它自然会会知道应该接收什么部件，并改善其划分。

由此，RPP 通过像素级部件再分配，使得每个 branch 可自由选择像素；并依据“记忆”中所熟悉的相应部件的概念，提纯各个部件。具体做法不再赘述，相信结合这一理解看 PCB，RPP 也将迎刃而解。

#### **为什么 Partial re-ID 更难？** 

实际的 re-ID 系统经常遭遇一个困难：行人仅仅被部分成像，如图 2 所示。

![1563884041920](C:\Users\j00496872\Desktop\Notes\raw_images\1563884041920.png)

​							图 2：在 partial re-ID 中，每个行人仅仅被部分成像，且缺失比例并不固定

直觉上，大家往往认为 partial re-ID 更难，要解决这个问题，就必须深入了解其更难的背后原因。首先，部分成像意味着信息损失，除此之外，还有两项额外的困扰，如下图中 (a)，(b) 所示：

![1563884084256](C:\Users\j00496872\Desktop\Notes\raw_images\1563884084256.png)

​												图 3：部分成像下 re-ID 的困难 (a)，(b) 及解决思路 (c)

(1) 首先，部分成像加剧了人体的空间错位。在图 3 (a) 中，尽管两幅图像其实含有同一个行人，且姿势、视角完全一样，但由于部分成像，导致二者之间存在很严重的空间错位；

(2) 另外，部分成像还引入了额外的干扰噪声。在图 3 (b) 中，左图对应的下半身区域不仅不再提供应有的鉴别线索，还产生了相对右图的干扰噪声（如果直接提取左右两幅图像的全局特征并作对比）。

为解决上述两个问题，提高 partial re-ID 准确率，一个非常直观的做法是——在比较两幅图像时，仅仅比较其共同可见的部分。然而这时，直觉和习惯思维又很容易将我们拽到使用语义部件这样一个做法上，即：给定两幅待比较的 partial image，先区分哪些语义部件可见，并提取相应的语义部件特征，比较二者共同可见的语义部件的部件特征。

但是，沿袭 PCB 工作的思路，本文继续坚定地认为：具象的语义部件不是必须，抽象的部件也奏效、甚至更好，从而有了如图 3 (c) 所示的思路：在完整图像上预先定义部件划分，然后在 partial image 上识别哪些部件可见，为每个抽象部件提取相应的部件特征。

#### **简介** 

行人再识别需要在行人图像库中，检索出特定身份行人的所有图像。尽管近年来进展迅速，但在实际应用之前，仍然遇到了一系列严峻挑战，其中之一是局部成像问题。在实际的 re-ID 系统中，一个行人可能被其他物体部分遮挡，或是正在走出摄像机视场，因此相机经常无法对行人进行全身成像，产生所谓的**局部成像下的行人再识别问题——partial re-ID**。

![1563849545554](C:\Users\j00496872\Desktop\Notes\raw_images\1563849545554.png)

直觉上来讲，局部成像必然加大行人检索难度；若仔细分析可以发现，相较于整体的行人再识别，局部成像又额外引入了两项特有挑战：

1. ==局部成像加剧了查询（query）图像与库（gallery）图像之间的空间错位==。全局 re-ID 场景下，空间错位主要源自行人姿态变化和观察视角的变换；然而在局部成像条件下，即便两个行人姿态相同，从同一个视角观察，两张图像间依然存在严重的空间错位（如图1（a））。
2. 如果生硬地比较全身图像和半身图像，二者之间不共享的区域（如图 1（b）中蓝色区域）不仅不再提供有益的线索，反而引入了额外的干扰噪声。这种额外噪声在对比两幅缺失程度不同的图像时也会发生。

针对上述挑战，旷视研究院提出可见部件感知模型 VPM。给定一幅行人图像，==VPM 能够感知哪些区域缺失、哪些区域可见，通过聚焦于两幅图共享的区域，VPM 避免或是说缓解了上述与局部重识别相关的两个特殊困难（如图1（c））==。

值得强调的是，==VPM 不依赖于头部、躯干等语义部件，而是依赖于预先定义的方形区域作为部件==。这种做法被 PCB 推广，其性能在全身行人在识别问题上已超过**语义部件特征学习**。本文把这种思路进一步延续：部件特征学习并不需要依赖人类习惯的语义部件，采用预先定义的方形部件高效且准确率可能更高。VPM 正是由于采用这种做法，==不再需要代价高昂的语义部件学习，仅仅通过自动监督学习，即可获得最关键的可见部件感知能力==。

具体而言，旷视研究员首先在完整出现了人体的图像上定义一系列区域。在训练过程中，给定局部行人图像，VPM 可以学习去定位所有在卷积特征图上的预定义区域。之后，VPM 会感知可见的区域，并学习区域层级的特征。在测试过程中，给定两张待比较的图像，VPM 首先会计算其共享区域之间的本地距离，然后得出两张图像的总体距离。

#### **方法** 

##### **VPM 结构**

![VPM结构图示](C:\Users\j00496872\Desktop\Notes\raw_images\1563849834381.png)     

​																			图2: VPM结构图示

VPM 是一个全卷积网络，结构如图 2 所示。本文在完整的行人图像上预先定义一个固定的部件分割，将图像分成 p 个部件（如图 2 分成上、中、下三个部件，即 p=3）。对于每一幅行人图像，VPM 输出固定数量的部件特征，以及相应的部件可见性得分。

注意，即使当前输入图像有一些部件不可见（例如图 2 中输入图像的下端部件实际不可见），VPM 仍然会为所有部件分别产生一个部件特征（包括那些不可见部件），但不可见部件的可见性得分将很低（趋于零）。这样，VPM 就能够知道哪些部件特征有效，哪些部件特征无效、不予采信。

为了实现上述功能，==VPM 在卷积层输出 Tensor T 上附加一个部件定位器和一个部件特征提取器==，前者通过自监督学习，学习 Tensor T 上的部件位置（及可见性得分），接着，后者则为每个部件生成一个相应特征。

自监督学习的构建非常直观，如图 2 所示。本文在完整的行人图像上预先定义一个固定的部件分割，将图像分成 p 个部件，然后裁剪，把裁减后的图像缩放到固定尺寸输入给 VPM。由于裁减参数可自动获取，从而自然知道哪些部件是可见的（如图中的上、中两个部件），哪些部件是不可见的（如图中的下端部件）。具体训练方法请参见“训练VPM”。

- ##### 部件定位器

部件定位器直接在 T 上预测各个部件 pixel-wise 的分布（也可以理解为一个图像分割器，只不过分割的对象是预先定义好的部件），从而感知哪些区域可见。为此，部件定位器在 T 上使用一层 1 × 1 卷积及一个 Softmax 函数来构建一个 pixel-wise 的部件分类器，这个公式并不必要，但是为了后面引用时清晰明确，将其如下列出：

 ![1563850134212](C:\Users\j00496872\Desktop\Notes\raw_images\1563850134212.png)

这个部件分类器实际上将产生 p 个分布概率图，每个分布概率图对应一个预先定义好的部件。这个分布概率图以 soft mask 的形式，直接指示出各个部件的位置。如果一个部件实际上不可见，那么对应于它的分布概率图应该处处为零，即各个像素属于这个部件的概率很小。

自然地，把各个概率图加起来，即可得到相应的区域可见性得分 C。这个做法非常直观：如果一个部件的分布概率图处处很小，那么这个部件可见性则很低（即可能不可见）。

- ##### 部件特征提取器

得到部件的概率分布图后，就可以简单地利用带权池化提取部件特征。公式同样很简单：

 ![1563850173506](C:\Users\j00496872\Desktop\Notes\raw_images\1563850173506.png)

再次强调，通过上述公式，VPM 会给每个预先定义好的部件产生一个特征，即使某个部件实际不可见，但这没关系，因为实际上已知道这个部件不可见，因此可不采信这个部件特征。具体如下节介绍。

#####  **使用 VPM**

给定两幅待比较的图像$I^k$ ,$I^l$，VPM 将提取其部件特征，并分别预测所有部件的可见性分数，即$\{f_{i}^k,C_i^k\}$,$\{f_i^l,C_i^l\}$。为了度量两幅图像的相似性，首先计算各个部件之间的欧氏距离 $D_i^{kl} = ||f_i^k - f_i^l|| (i=1,2,...，p)$。在部件距离的基础上，结合部件可见性得分，VPM 能够推导两幅图像间的总体距离：

![1563850464614](C:\Users\j00496872\Desktop\Notes\raw_images\1563850464614.png)      

上式的效果是：==采信可见区域之间的距离，忽视不可见区域之间的距离==。换而言之，可见部件的距离将主导总体距离 $D^{kl}$；相反，如果一个部件在任何图像中没出现，那么其部件特征则被认为不可靠，无法对 $D^{kl}$ 产生明显影响。

这样的调用过程非常高效：==与 PCB 这种实用方法相比，VPM 仅仅增加了一层卷积运算用于预测部件可见性，计算距离则几乎不增加时间（仅仅多了公式 4 所示的加权平均）。==这使得 VPM 成为了为数不多的、能够在 Market-1501 数据集上开展 partial re-ID 实验的方法（也具有在大规模实际数据集上应用的潜力）。

#####  **训练 VPM**

VPM 的训练包含 1）部件定位器的训练和 2）部件特征提取器的训练。两者在 Tensor T 之前共享卷积层，并以多任务的方式被端到端训练。==部件定位器的训练依靠自监督学习，而训练部件特征提取器也需要自监督信号进行辅助==。由实验可知，自监督学习对 VPM 的性能至关重要。

- ##### 自监督

自监督对于 VPM 十分关键，它监督 VPM 学习部件定位器，并要求 VPM 在学习部件特征时，放弃对不可靠的部件特征的监督，仅仅对可见区域施加监督。

部件定位器的训练类似 Segmentation 训练，这里仅强调一下：Label 信息由自监督产生。部件特征的学习虽然也采用了常用的分类+度量学习联合训练，但需要做一些重要调整，如图 3 所示。

![1563850618890](C:\Users\j00496872\Desktop\Notes\raw_images\1563850618890.png)      

​		图 3： VPM 通过辅助性自监督学习区域特征

由于 VPM 会为所有部件分别生成一个部件特征，这导致在学习特征时出现一个非常重要的问题：只有可见部件的特征被允许贡献训练损失。借助自监督信号，动态地为特征学习选择可见区域。实验结果表明，==如果不加区分地对所有部件特征施加监督，re-ID 准确率将剧烈降低==。

总结一下，自监督对训练 VPM 的贡献体现在 3 个方面：

1. 自监督生成 Pixel-wise 的部件标签用以训练部件定位器（类似于 Segmentation）；
2. 在利用分类损失函数（Softmax Loss）学习部件特征时，自监督使 VPM 仅仅关注可见部件；
3. 利用度量学习（Triplet）学习部件特征时，自监督使 VPM 专注于图像的共有区域。

####  **实验** 

##### **大规模数据集实验**

本文首先利用两个大型全身 re-ID 数据集（Market-1501 和 DukeMTMC-reID）合成相应的部分成像 re-ID 数据集上的实验评估 VPM 的有效性。

本文用了两种基线作为对比：首先是一个学习全局特征的基线，它是利用分类损失函数和三元组损失函数联合训练的；第二个基线则是非常流行的全身部件特征模型 PCB。实验结果如表 1 所示，可以看到 VPM 相对这两种基线都有明显提高。

![1563850710521](C:\Users\j00496872\Desktop\Notes\raw_images\1563850710521.png)     

​															表 1： VPM、baseline 与 PCB 之间的对比

##### **对比 SOTA**

本文在两个公开数据集 Partial-REID 和 Partial-iLIDS 把 VPM 与当前最佳方法做了对比。本文训练了 3 个版本的 VPM：

1）VPM(bottom)，训练时总是丢弃随机比例的上半身，而下部区域可见；

2）VPM(top)，训练时总是丢弃随机比例的下半身，而图像的上部区域总是可见；

3）VPM(bilateral)，训练时，图像的上部和下部区域都有可能被随机比例丢弃。对比结果如表 2 所示。

![1563850792350](C:\Users\j00496872\Desktop\Notes\raw_images\1563850792350.png)      

表 2： VPM 在 Partial-REID 和 Partial-iLIDS 上的评估结果

可以看到，训练时的 crop 策略对性能是有影响的，VPM（bottom）结果比较差。这是因为首先大部分数据集以及在实际情况中，大部分图像是下半身缺失，而上半身可见，VPM（bottom）在训练时的策略相反，背离了现实；此外，一般来讲，上半身能够提供的可鉴别线索本身就更为丰富。

文中还进行了一些其它有意思的实验，例如通过 Ablation Study 分析各个环节中自监督对 VPM 性能的影响，VPM 定位各个部件的可视化实验。

#### **结论**

本文提出一个基于可见部件感知的行人特征学习方法——VPM，它可解决局部成像下的行人再识别问题。==延续 PCB 的思路，VPM 没有采用语义部件这种直观做法，而是采用了均匀分割产生若干预定义的部件==。通过自监督学习，VPM 能够感知哪些部件可见、哪些部件缺失，并决定应该如何具体对比两幅图像。实验结果表明，VPM 同时超越了全局特征学习基线和部件特征学习基线，并在公开的 partial re-ID 数据集上取得了国际领先水平。