## 网络搜索 - Block搜索方案

#### 目标

采用合适的搜索空间和搜索算法，通过NAS得到新的网络结构，替换人脸检测模型的backbone，新模型在D上推理时间减少的同时，精度不下降。

![img](D:\Notes\raw_images\clip_image002.png)

 

#### 基线模型

Backbone 

![img](D:\Notes\raw_images\clip_image004.png)

K3C16S2表示 kernel_size=3, out_channel=16, stride=2

参数量：4710160



#### 性能指标

Widerface验证集（3226图，推理尺寸800*640，单尺度）

| AP(Easy)   | 0.904 |
| ---------- | ----- |
| AP(Medium) | 0.866 |
| AP(Hard)   | 0.627 |

 Z4测试集1（1031图）

| AP             | 0.5420 |
| -------------- | ------ |
| AP(size>50x50) | 0.9072 |

 Z4测试集2（5000图）

| AP             | 0.6346 |
| -------------- | ------ |
| AP(size>50x50) | 0.9071 |

 

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image006.png)

 

### 前期调研

搜索空间，搜索策略和性能评估策略是NAS问题的三个关键要素。

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image008.png)

### NasNet（CVPR2018）

论文地址：https://arxiv.org/abs/1707.07012

提出了cell-based 的搜索空间（如下），该搜索空间后续被广泛采用

**搜索空间：**

输入：前n-1个block的输出中选取2个

OP:

• identity • 1x3 then 3x1 convolution • 1x7 then 7x1 convolution • 3x3 dilated convolution • 3x3 average pooling • 3x3 max pooling • 5x5 max pooling • 7x7 max pooling • 1x1 convolution • 3x3 convolution • 3x3 depthwise-separable conv • 5x5 depthwise-seperable conv • 7x7 depthwise-separable conv

输出：Node内Add，Node间concat

超参：每个block中Node个数，block总数，reduction次数。

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image010.jpg)

**搜索策略：**RL-based （PPO）

**性能评估策略：**对于搜索出的每一个网络，完整训练若干epoch，评估验证集上的精度。

**搜索耗时：**2000 GPU-DAYS



### AmoebaNet（AAAI2019）

论文地址：https://arxiv.org/abs/1802.01548

第一个采用EA-based搜索策略达到SOTA的方法，在进化算法中使用了年龄进化的策略，在进化时倾向于选择更年轻的模型。

**搜索空间：**cell-based search space，与NasNet相同。

**搜索策略：**EA-based

(1) 初始化时随机产生P个模型。

(2) 每一次从现存的P个模型中，先随机选择S个模型（S<P），然后从S个模型中选择一个精度最高的模型，令其产生后代。

(3) 产生后代时要进行变异，变异的操作包括随机替换卷积操作（op mutation）和随机替换输入Feature Map（hidden state mutation）。在每次变异中，只会进行一次变异操作。

(4) 把新模型放入现存模型队列中，同时删除最“老”（存在时间最长，直接删除队列中的第一个元素即可）的模型。

**性能评估策略：**对于搜索出的每一个网络，完整训练若干epoch，评估验证集上的精度。

**搜索耗时：**3150 GPU-DAYS



### ENAS（IMCL2018）

论文地址：https://arxiv.org/abs/1802.03268

提出了参数共享策略（即one-shot方法），大大减少了搜索网络结构所需的时间。

**搜索空间：**cell-based search space，在NasNet基础上进行了精简，保留以下OP：

• identity • 3x3 average pooling • 3x3 max pooling • 3x3 convolution • 3x3 depthwise-separable conv • 5x5 convolution • 5x5 depthwise-seperable conv 

**搜索策略：**RL-based （policy gradient）

**性能评估策略：**训练supernet，对于搜索出的每一个网络结构，直接使用supernet中对应的权重，评估验证集上的精度。

**搜索耗时：**0.45 GPU-DAYS



### MnasNet（CVPR2019）

论文地址：https://arxiv.org/abs/1807.11626?context=cs.LG

1. 针对硬件搜索网络结构，直接在硬件平台上测量latency。

2. 将latency加入RL的reward中。

3. 提出新的搜索空间。

**搜索空间：**mobilenetv2-based search space

ConvOP：conv、depthwise-separable conv、mobile_inverted_bottleneck(expand_raio=3 or 6)

Conv kernel size：3x3、5x5

SkipOP：maxpool3x3、avgpool3x3、identity、no

SE ratio：0、0.25

Output channel size：F  {0.75, 1.0, 1.25} to MobileNetV2

LayerNumber：N  {0, +1, -1} based on MobileNetV2

超参：Block总数

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image012.jpg)

**搜索策略：**RL-based （PPO）

希望搜索出同时具有高精度和低的前向推理延迟的网络结构，测量其在实际平台上的延迟，放入reward中。reward如下：

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image014.jpg)

**性能评估策略：**对于搜索出的每一个网络，完整训练若干epoch，评估验证集上的精度，在实际平台上测试推理时延。

**搜索耗时：**288TPU-days (on ImageNet)



### ProxylessNaS（ICLR2019）

论文地址：https://arxiv.org/pdf/1812.00332.pdf

利用通道二值化的手段解决了one-shot方法和DARTS中显存占用过大的问题。

通过采样方式建立op延迟模型，在损失函数中增加了额外的正则项，使得搜索时可以考虑到latency

**搜索空间：**新增了7x7的卷积核，cell-based search space（cifar），mobilenetv2-based search space （ImageNet）

**搜索策略：**gradient descent

**性能评估策略：**搜索过程中不涉及性能评估。

**搜索耗时：**8.3GPU-days

 

### DARTS（ICLR2019）

论文地址：https://arxiv.org/abs/1806.09055

通过引入relaxation op，将选择最优op这一离散的问题松弛成了求解最优结构权重这一连续问题，从而使用梯度下降优化这一问题。

**搜索空间：**cell-based search space，在ENAS基础上进行了改动，包含以下OP：

• identity • 3x3 average pooling • 3x3 max pooling • 3x3 dilated separable conv • 3x3 depthwise-separable conv • 5x5 dilated separable conv • 5x5 depthwise-seperable conv 

**搜索策略：**gradient descent

**性能评估策略：**搜索过程中不涉及性能评估。

**搜索耗时：**1.5GPU-days



### PC-DARTS（ICLR2020）

论文地址：https://arxiv.org/abs/1907.05737v1

1. 只在部分通道中进行可微结构搜索，大大减小了DARTS中所需要的显存。

2. 提出edge-normalization，解决了搜索结果不稳定的问题（搜索一段时间后collapse，大量选取skip OP）。

**搜索空间：**同DARTS 

**搜索策略：**gradient descent

**性能评估策略：**搜索过程中不涉及性能评估。

**搜索耗时：**0.1GPU-days

 

### Fair-DARTS

论文地址：https://arxiv.org/abs/1911.12126

1. 通过给予每个 op 独立的结构化参数，解决DARTS搜索后期过多选取skip OP的collapse问题

2. 通过引入0-1 loss，使op结构化参数逼近0或1，缩小连续的结构参数离散化时的gap。

**搜索空间：**同DARTS 

**搜索策略：**gradient descent

**性能评估策略：**搜索过程中不涉及性能评估。

**搜索耗时：**0.5~3GPU-days

 

### DARTS+

论文地址：https://arxiv.org/abs/1909.06035

提出早停准则，避免了DARTS搜索后期的collapse问题，缩短搜索时间的同时提高了性能。

**搜索空间：**同DARTS 

**搜索策略：**gradient descent

**性能评估策略：**搜索过程中不涉及性能评估。

**搜索耗时：**0.2~0.6GPU-days

 

### 搜索算法与搜索空间选取

| 搜索算法     | 搜索空间                      | 搜索策略                     | 搜索耗时   （GPU-DAYS）   |
| ------------ | ----------------------------- | ---------------------------- | ------------------------- |
| NasNet       | Cell-based                    | RL-based                     | 2000                      |
| AmoebaNet    | Cell-based                    | EA-based                     | 3150                      |
| ENAS         | Cell-based                    | RL-based   (policy gradient) | 0.45                      |
| MnasNet      | mobilenetv2-based             | RL-based   (PPO)             | 288TPU-days (on ImageNet) |
| ProxylessNas | Cell-based/ mobilenetv2-based | gradient descent             | 8.3                       |
| DARTS        | Cell-based                    | gradient descent             | 1.5                       |
| PC-DARTS     | Cell-based                    | gradient descent             | 0.1                       |
| Fair-DARTS   | Cell-based                    | gradient descent             | 0.5~3                     |
| DARTS+       | Cell-based                    | gradient descent             | 0.2~0.6                   |



### 搜索算法选取

从搜索耗时上，排除NasNet与AmoebaNet。MnasNet的搜索耗时是在ImageNet上，而其他均基于cifar10。

- ProxylessNas未提供任何搜索代码，实现难度大。

- ENAS搜索代码已开发，已在车牌识别场景测试。

- MnasNet搜索代码已开发，已在车牌识别场景测试。

- DARTS官方代码已开源，已在cifar10上测试。


 目标是搜索高精度、低时延的人脸检测模型，ENAS的reward中需增加时延项，DARTS类算法的loss中不含时延项，不能简单的加入（时延不可微），MnasNet的reward同时考虑了精度和时延。

选取MnasNet的搜索算法。



### 搜索空间选取

选取Cell-based的搜索空间。

目前算法的搜索空间主要有两类：cell-based与 mobilenetv2-based，cell-based更灵活，搜索空间更大，mobilenetv2-based基于mobilenetv2的先验，收敛更快，耗费显存更少。

**Cell-based：**

输入：在上一个block的输出加上前n-1个node的输出中选取2个

Op：• identity • 3x3 average pooling • 3x3 max pooling •卷积op根据D上测试结果决定

输出：Node内Add，Node间concat

超参：每个block中Node个数，block总数，reduction次数。按参数量的量级确定

![img](file:///C:\Users\J00496~1\AppData\Local\Temp\msohtmlclip1\01\clip_image015.jpg)

 

**mobilenetv2-based：**

ConvOP：根据D上测试结果决定

Conv kernel size：3x3、5x5

SkipOP：maxpool3x3、avgpool3x3、identity、no

SE ratio：0、0.25 

Output channel size：F  {0.75, 1.0, 1.25} to MobileNetV2按参数量的量级确定

LayerNumber：N  {0, +1, -1} based on MobileNetV2按参数量的量级确定

超参：Block总数，按参数量的量级确定