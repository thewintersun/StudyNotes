## Hierarchical Personalized Federated Learning for User Modeling

论文地址：https://dl.acm.org/doi/abs/10.1145/3442381.3449926

作者：Jinze Wu1 , Qi Liu1,∗ , Zhenya Huang1 , Yuting Ning1 , Hao Wang1 , Enhong Chen1 Jinfeng Yi2 , Bowen Zhou2

机构：中科大、京东

发表：WWW ’21, April 19–23, 2021, Ljubljana, Slovenia



### 摘要

用户建模旨在从用户的行为中捕捉用户的潜在特征，并广泛应用于众多应用中。通常，集中式用户建模存在隐私泄露风险。相反，联合用户建模期望通过联合学习为用户建模提供安全的多客户端协作。现有的联邦学习方法主要是针对一致性客户端设计的，不能直接应用于实际场景，不同客户端通常存储不一致的用户数据。因此，设计一个能够更好地适应用户建模任务的合适的联合解决方案是一项至关重要的需求，但是，它会遇到以下关键挑战：

1）统计异构性。用户数据在不同客户端的分布并不总是独立同分布，从而导致个性化客户端； 

2)  隐私异质性。用户数据包含公共和私人信息，它们具有不同的隐私级别。这意味着我们应该平衡要共享和保护的不同信息； 

3) 模型异质性。使用客户端记录训练的本地用户模型是异构的，需要在服务器中灵活聚合。

在本文中，我们提出了一种新颖的客户端-服务器架构框架，即分层个性化联邦学习（HPFL），以在具有不一致客户端的用户建模中服务于联邦学习。在该框架中，我们首先定义分层信息以对具有隐私异构性的数据进行精细划分。在此基础上，客户端训练一个用户模型，该模型包含为分层信息设计的不同组件。此外，客户端处理细粒度的个性化更新策略来更新个性化用户模型以实现统计异质性。相应地，服务端完成差异化的组件聚合策略，在隐私和模型异构的情况下灵活聚合异构用户模型。最后，我们对现实世界的数据集进行了广泛的实验，证明了 HPFL 框架的有效性。

![image-20220228164805765](D:\Notes\raw_images\image-20220228164805765.png)

图 1：标准联邦学习（左）和我们用于用户建模的分层个性化联邦学习（右）之间的差异。

标准 FL 只是不加选择地聚合和更新一致的整个用户模型，而 HPFL 则独立地对异构模型的不同组件进行分区和处理。顶部显示了具有全局模型的服务器。底部显示具有 Non-IID 数据和本地用户模型的客户端。每轮包括四个步骤：在本地训练模型、将模型发送到服务器、在服务器中聚合模型以及为客户端更新模型。

<img src="D:\Notes\raw_images\image-20220228165353862.png" alt="image-20220228165353862" style="zoom:80%;" />

​												图 2：具有差异化组件聚合和细粒度个性化更新策略的分层个性化联合学习框架。