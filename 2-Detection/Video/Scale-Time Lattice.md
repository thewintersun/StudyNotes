## Optimizing Video Object Detection via a Scale-Time Lattice

论文地址： https://arxiv.org/abs/1804.05472v1

作者：Kai Chen, Jiaqi Wang, Shuo Yang, Xingcheng Zhang, Yuanjun Xiong, Chen Change Loy, Dahua Lin

机构：CUHK, 商汤，Amazon Rekognition

发表：CVPR 2018

代码地址：https://github.com/hellock/scale-time-lattice （等待）

作者项目介绍地址：https://github.com/guanfuchen/video_obj

项目地址：http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/

文章地址：https://zhuanlan.zhihu.com/p/38890190



在物体检测与识别领域，香港中文大学-商汤科技联合实验室在CVPR 2018发表论文，提出基于尺度-时间网格的视频中物体检测算法，解决如何优化和平衡视频物体检测中精度和速度的难题。

#### **简介**

本文主要研究如何更好地优化和平衡视频中物体检测的准确率和检测速度。物体检测器为了达到高准确率，往往需要使用高性能的卷积神经网络来提取图像特征，导致检测速度难以满足实时性的需求。解决这个问题的关键在于寻求一种有效的方式，在准确率和检测速度之间作出平衡。为了寻找一个良好的平衡点，之前的研究工作通常集中在如何优化网络结构上。==本文提出一种新的方法，基于尺度-时间网格（Scale-Time Lattice，简记为ST-Lattice）来重新分配计算资源。==

提出的方法在ImageNet VID 数据集上达到了 79.6 mAP（20fps）和 79.0 mAP（62 fps）的准确率和速度。本文的主要贡献有：

- 提出了==尺度-时间网格==，其为算法提供了丰富的设计空间来对物体检测性能进行优化；
- 基于尺度-时间网格，提出了==新的视频中物体检测的框架==，实现了优异准确率和快速检测速度的平衡；
- 设计了一些新的技术模块，包括==高效的传播模块==和==动态的关键帧选取模块==。

#### **基本思想**

视频中相邻帧之间有着很强的连续性和信息冗余性，为了提高效率，应该充分利用这些性质来设计新的检测框架。之前的方法已经对视频中的物体检测作了很多探索，通常包含若干个步骤，例如基于单帧的物体检测，进行跨时间的传播和空间上位置的修正等，如何用一种更高效的方式将这些独立的步骤结合起来是一个值得研究的问题。

本文提出的基本思想是在一个计算网格中对计算资源进行更好的分配，==将精确但速度较慢的静态图像物体检测器应用于稀疏的关键帧上==，然后==利用一些简单高效的网络在时间和空间两个维度上不断地传播和修正这些检测结果，以达到更好的平衡==。

本文探索了使用一种新的方法，在规模时间内重新分配计算空间。具体来说，在自然视频中的帧中存在很强的连续性，这表明了另一种可选的减少计算成本的方法，即时序上传播计算。通常来说，基于视频的目标检测方法是一个多步骤的过程，先前研究的任务中，比如基于图像的目标检测，时序传播，稀疏到细致化的微调等等都是这个过程中的单一步骤。然而单一步骤的提升尽管被研究了很久，但是一个关键问题仍然悬而未决：“什么是最具成本效益地将它们结合起来的策略？”

Scale-Time Lattice是一个统一的形式，其中上面提到的步骤是Scale-Time Lattice中有向连接的不同节点。 从这个统一的观点来看，可以很容易看出不同的步骤如何贡献以及如何计算成本分配。



#### **尺度-时间网格**

本文将尺度-时间网格表示成一个有向无环图（如图1所示）。图中的每一个节点都表示某个图像尺度和时间点的中间结果，即一系列检测框。这些节点以类似网格的方式关联起来：==从左到右遵循时间顺序，从上到下图像尺度（分辨率）逐渐提高==。图中的一条边代表一个特定的操作，以一个节点的结果作为输入，输出另一个节点的检测结果。我们在图中定义两种操作，==时间传播（temporal propagation）和空间修正（spatial refinement）==。它们分别对应图中横向边和纵向边。==时间传播是在同一图像尺度下，在相邻的帧之间进行检测框的传播==。==而空间修正是在同一帧下，对检测框的位置进行修正，获得更高图像尺度下的检测框结果==。在尺度-时间网格中，检测结果会通过上述操作从一个节点传播到另一个节点，最终到达最底端的所有节点，也即在最大的图像尺度上每帧的检测结果。

![img](https://pic2.zhimg.com/80/v2-2157753915ad6c166fff0d45161b2491_hd.jpg)

​														图1：尺度-时间网格示意图

网络结构如下所示，其中小红点表示在关键帧的检测，方格点表示尺度-时间格子，也就是空间-时间格子的结果，其中黑色虚线表示直接映射或者缩放，蓝色实线表示在空间上的传播，蓝色实线表示在空间上的微调，图中水平方向的操作是在时间上的传播，垂直方向的操作是在空间上的细化，其中PRU表示Propagation and Refinement Unit，即传播细化单元，这个基本结构是构成格子的主要组件，用来完成时间传播和空间细化。PRU将两个连续的关键帧的检测结果作为输入，然后传播到参考帧中，并且通过细化输出到下一空间尺度。

![1574414910798](D:\Notes\raw_images\1574414910798.png)

**基于尺度-时间网格，本文的视频物体检测算法被分为以下3 个步骤：**

1. 在稀疏的关键帧上（用基于静态图像的物体检测器）进行检测，得到稀疏节点上的结果；
2. 规划一条从上述稀疏的节点到稠密的节点的路径；
3. 基于上述路径将关键帧上的检测结果传播到中间帧，并进行位置修正。

尺度-时间网格的框架为算法提供了丰富的设计空间来平衡优化视频中物体检测精度和速度。==检测所需要的总时间是路径中所有边的时间之和，包括单帧物体检测器的时间以及传播和修正所用的时间。==可以通过对不同的边上分配不同的计算时间，来达到性能与时间上的期望平衡点。

![img](https://pic3.zhimg.com/80/v2-820b93a2ee07e23afe6ac2ed1caea51e_hd.jpg)

​							图2：尺度-时间网格中的时间传播网络（T）和空间修正网络（S）

#### **不同模块的实现**

**传播和修正单元（Propagation and Refinement Unit，PRU)**

传播和修正单元（如图2所示）以相邻两个关键帧的结果作为输入，使用时间传播网络将结果传播到中间帧上，然后使用空间修正网络将结果进行空间位置上的修正。时间传播网络主要用于考虑视频中的运动信息，来预测两帧之间较大的位移。而空间修正模块则通过回归检测框位置的偏差，来修正检测框本来的误差和传播带来的误差。这两种操作不断迭代进行来获得最终的检测结果。

在时间传播网络中，算法使用两帧之间的运动历史图像（Motion History Image，MHI）来表示运动信息，将其输入到网络中，回归物体在这段时间内的位移。==相对于光流等常用的运动表示，MHI 的计算速度非常快，使得空间传播网络能够保持较高的效率==。

不同于DFF使用光流来传播关键帧的稠密特征，本文主要==使用MHI来编码运动信息来传播帧间运动特征==，下图比较了在不同间隔的关键帧下的不同传播方法的精度，左图是整体精度比较，右图是基于不同的目标运动的检测精度比较，其中比较主要包括Interpolation、RGB差值和MHI这三种方法，另外从右图中可以看出使用MHI方法精度提升的主要目标位快速运动的目标。

![1574415359969](D:\Notes\raw_images\1574415359969.png)

Figure 7: Results of different propagation methods under different key frame intervals. (Left) the overall results. (Right) Detailed results based on different object motion.

在空间修正网络中，算法采用与Fast R-CNN 相同的结构，以当前帧的 RGB 图像作为输入，来回归检测框的偏差。这两个小网络在训练时通过一个多任务的损失函数同时进行优化。

**关键帧选取**

关键帧的选取对最终的检测速度和准确率有着重要的影响。最简单直接的方法就是在时间轴上均匀地选取关键帧，之前的绝大多数方法也都采取了该策略。==但本文考虑到帧与帧之间的信息冗余度不同，并不是每一帧都有同等重要的地位，所以需要一种非均匀的采样策略，在物体运动较快、传播难度大的时间段内多选取关键帧，反之则少选取关键帧。==

具体过程如下：==首先在均匀选取的非常稀疏的帧（例如每隔24帧）上进行单帧的物体检测，然后根据检测结果来衡量相邻两个关键帧之间传播的难易程度，如果难易程度低于某个阈值，则在这两帧之间插入一个额外的关键帧。计算难易程度时本文考虑了两个因素，即框的大小以及物体运动快慢==，具体公式参见原文。

![1574415050406](D:\Notes\raw_images\1574415050406.png)

**时间管道重打分（Tube Rescoring）**

由于时间上的检测框传播，获得的检测结果并不是独立的逐帧结果，而是自然串联成一个个的物体时间管道（Object Tube）的，那么可以对这些物体时间管道来进行重新分类。本文==训练了一个 R-CNN 作为分类器==，对于每个物体时间管道，均匀选取其中 K 帧作为输入，以它们的平均值作为新的分类结果，==根据新的分类结果来调整物体时间管道中每个框的分数。==

### **实验结果**

图3展示了本文基于尺度-时间网格算法的检测速度（fps）和准确率（mAP）的曲线，并和之前的方法进行比较。可以看到本文方法优于 baseline 和之前性能先进的方法。

文中实验结果比较了常用的在VID数据集上实验的方法，其中包括DFF、TPN+LSTM、FGFA和D&T，以及本文提出的scale-time lattice方法，具体比较结果如下图所示：

![img](https://pic3.zhimg.com/80/v2-e07264ee282ad8d096c00b8f26e4cb52_hd.jpg)

​										图3：不同视频中物体检测算法检测速度和精度的比较

#### **结论**

针对视频中的物体检测，本文提出了尺度-时间网格这个灵活的框架，其提供了丰富的设计空间来解决如何平衡准确率和检测速度的挑战。该方法==将单帧检测、时间传播、多尺度空间处理结合起来==解决这个问题。实验结果展示了基于该框架的多种设计和配置，能够达到与当前先进性能方法近似的准确率，但检测速度则获得了大幅提高。该框架不仅可以用于物体检测，也可以应用在其他视频相关的任务，如物体分割、物体跟踪等。