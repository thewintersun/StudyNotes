## 视频目标检测 - 快速的方法调研

https://paperswithcode.com/task/video-object-detection

论文搜索来源Paperswithcode> Video Object Detection

### Looking Fast and Slow: Memory-Guided Mobile Video Object Detection

论文地址：https://arxiv.org/abs/1903.10172v1

作者：  Mason Liu, Menglong Zhu, Marie White, Yinxiao Li, Dmitry Kalenichenko

机构： 康奈尔大学，Google AI

代码地址：https://github.com/tensorflow/models/tree/master/research/lstm_object_detection

其他实现：https://github.com/vikrant7/pytorch-looking-fast-and-slow

摘要：

In addition, we show that the memory contains enough information for deploying reinforcement learning algorithms to learn an adaptive inference policy. Our model achieves state-of-the-art performance among mobile methods on the Imagenet VID 2015 dataset, while running at speeds of up to 70+ FPS on a Pixel 3 phone.

人类简单的一瞥，视觉系统就能够对一个复杂的环境有整体的理解, 进而对象识别和检测，而这种能力是依赖于相关的先验知识的。本文讨论了在计算机视觉系统中==使用memory 不仅能提高视频流中物体检测的准确性,还能减少计算时间==。通过交叉使用传统的特征提取器与极轻量级的特性提取器, 识别场景中的要点, 我们表示在使用temporal memory 时仅需要最小的计算就可以产生准确的检测效果。此外,我们表示memory包含足够的信息来部署强化学习算法来学习自适应推理策略。我们的模型在Imagenet VID 2015数据集的Mobile方法中获得了最先进的性能, 同时==在Pixel 3 手机上运行高达70 + FPS==的速度。

![1574407987137](D:\Notes\raw_images\1574407987137.png)

![1574410072057](D:\Notes\raw_images\1574410072057.png)

Figure 4: Our adaptive interleaved model uses an ultralightweight policy network to decide which feature extractor to run at each time step.

![1574410192043](D:\Notes\raw_images\1574410192043.png)

![1574409897189](D:\Notes\raw_images\1574409897189.png)

### Optimizing Video Object Detection via a Scale-Time Lattice

论文地址： https://arxiv.org/abs/1804.05472v1

作者：Kai Chen, Jiaqi Wang, Shuo Yang, Xingcheng Zhang, Yuanjun Xiong, Chen Change Loy, Dahua Lin

机构：CUHK, 商汤，Amazon Rekognition

发表：CVPR 2018

代码地址：  https://github.com/guanfuchen/video_obj（未开放）

https://github.com/hellock/scale-time-lattice （等待）

摘要：

本文主要研究如何更好地优化和平衡视频中物体检测的准确率和检测速度。物体检测器为了达到高准确率，往往需要使用高性能的卷积神经网络来提取图像特征，导致检测速度难以满足实时性的需求。解决这个问题的关键在于寻求一种有效的方式，在准确率和检测速度之间作出平衡。为了寻找一个良好的平衡点，之前的研究工作通常集中在如何优化网络结构上。==本文提出一种新的方法，基于尺度-时间网格（Scale-Time Lattice，简记为ST-Lattice）来重新分配计算资源。==

提出的方法在ImageNet VID 数据集上达到了 79.6 mAP（20fps）和 79.0 mAP（62 fps）的准确率和速度。本文的主要贡献有：

- 提出了==尺度-时间网格==，其为算法提供了丰富的设计空间来对物体检测性能进行优化；
- 基于尺度-时间网格，提出了==新的视频中物体检测的框架==，实现了优异准确率和快速检测速度的平衡；
- 设计了一些新的技术模块，包括==高效的传播模块==和==动态的关键帧选取模块==。

![examples](https://camo.githubusercontent.com/970616e4b24499fd8f66aa03aa04faa3875c3679/687474703a2f2f6d6d6c61622e69652e6375686b2e6564752e686b2f70726f6a656374732f53542d4c6174746963652f696d672f6578616d706c65732e676966)



### Mobile Video Object Detection with Temporally-Aware Feature Maps

论文地址：https://arxiv.org/abs/1711.06368v2

作者：  Mason Liu, Menglong Zhu

机构：Georgia Tech，Google

发表：CVPR 2018

代码地址: https://github.com/vikrant7/mobile-vod-bottleneck-lstm （Pytorch实现）

摘要：

本文介绍了一种在低功耗移动设备和嵌入式设备上实时运行的在线视频目标检测模型。我们的方法将快速的单张图像目标检测==与卷积长短时记忆(LSTM)层相结合==，创建一个交织的递归-卷积架构。此外，我们提出了一个有效的Bottleneck-LSTM层，与常规的LSTM相比，它显著降低了计算成本。我们的网络通过使用Bottleneck-LSTM来改进和传播跨帧的特征图，从而实现时间感知。该方法大大快于现有的视频检测方法，在模型大小和计算成本方面超过最快的单帧模型，同时获得的精度可与Imagenet VID 2015数据集上的其他模型相媲美。我们的模型在移动设备CPU上达到了高达15 帧的实时推理速度。

we use 256 × 256 input resolution

![img](https://github.com/vikrant7/mobile-vod-bottleneck-lstm/raw/master/lstm_ssd_intro.png)

![1574408310681](D:\Notes\raw_images\1574408310681.png)

Figure 2: An example illustration of our joint LSTM-SSD model. Multiple Convolutional LSTM layers are inserted in the network. Each propagates and refines feature maps at a certain scale.

![1574408480286](D:\Notes\raw_images\1574408480286.png)

Figure 3: Illustration of our Bottleneck-LSTM. Note that after the bottleneck gate, all layers have only N channels.

### Towards High Performance Video Object Detection for Mobiles

论文地址：https://arxiv.org/abs/1804.05830v1

作者：Xizhou Zhu, Jifeng Dai, Xingchi Zhu, Yichen Wei, Lu Yuan

机构： MSRA

代码地址：https://github.com/stanlee321/LightFlow-TensorFlow

摘要:

尽管视频对象在桌面gpu上获得了成功,但它的架构仍然对手机来说太重了。还不清楚稀疏特性传播和多帧特性聚合的关键原理是否适用于非常有限的计算资源。本文介绍了一种用于手机视频对象检测的轻量级网络架构。在稀疏关键帧上应用轻权重图像对象探测器。一个非常小的网络, 光流,是为在frames内建立通信而设计的。在关键帧上,设计了一个flow-guided GRU模块, 以有效地聚合特性。对于非关键帧, 执行稀疏特性传播。整个网络可以进行端到端的训练。该系统达到了60.2%的mAP 分数,速度为25.6fps ，华为Mate 8。

![1574413167023](D:\Notes\raw_images\1574413167023.png)

![1574413254452](D:\Notes\raw_images\1574413254452.png)