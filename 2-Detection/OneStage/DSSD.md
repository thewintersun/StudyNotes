### DSSD : Deconvolutional Single Shot Detector

论文地址：https://arxiv.org/abs/1701.06659

作者：Cheng-Yang Fu, Wei Liu, Ananth Ranga, Ambrish Tyagi, Alexander C. Berg

机构：UNC Chapel Hil,  Amazon Inc.

文章地址：https://zhuanlan.zhihu.com/p/33036037

SSD+TDM代码：https://github.com/MTCloudVision/mxnet-dssd



## 一、DSSD算法思想

DSSD是对SSD算法的优化改进，主要改进点如下：

1)提出基于top down的网络结构，用反卷积代替传统的双线性插值上采样。

2)在预测阶段引入残差单元，优化候选框回归和分类任务输入的特征图。

3)采用两阶段训练方法。

**主要解决问题:**

卷积神经网络在结构上存在固有的问题：高层网络感受野比较大，语义信息表征能力强，但是分辨率低，几何细节信息表征能力弱。低层网络感受野比较小，几何细节信息表征能力强，虽然分辨率高，但语义信息表征能力弱。SSD采用多尺度的特征图来预测物体，使用具有较大感受野的高层特征信息预测大物体，具有较小感受野的低层特征信息预测小物体。这样就带来一个问题：使用的低层网络的特征信息预测小物体时，由于缺乏高层语义特征，导致SSD对于小物体的检测效果较差。而解决这个问题的思路就是对高层语意信息和低层细节信息进行融合。作者采用Top Down的网络结构进行高低层特征的融合并且改进了传统上采样的结构。

虽然Top Down的方法来丰富特征信息的思想很容易理解，但是大多数论文中所说的特征图金字塔的构造方式各不相同，只是针对于特定的网络结构来做优化，比如FPN的网络结构只是针对resnet做了优化，文章中也没有提及过更换其他的基础网络的实验结果，普适度不够。==DSSD作者提出一种通用的Top Down的融合方法，使用vgg和resnet网络，以及不同大小的训练图片尺寸来验证算法的通用型，将高层的语义信息融入到低层网络的特征信息中，丰富预测回归位置框和分类任务输入的多尺度特征图，以此来提高检测精度。==在提取出多尺度特征图之后，作者提出由残差单元组成的预测模块，进一步提取深度的特征最后输入给框回归任务和分类任务。除了DSSD外，另外两篇文章FPN: Feature Pyramid Networks for Object Detection（以下简称FPN）和Beyond Skip Connections: Top-Down Modulation for Object Detection（以下简称TDM），也利用了Top Down融合的思想。

下图给出了Google TDM、DSSD和FPN的Top Down网络结构，在特征图信道融合的步骤中，他们用了不同的方法：==Google TDM使用的是concat操作，让浅层和深层的特征图叠在一起==。==DSSD使用的是Eltw Product（也叫broadcast mul）操作，将浅层和深层的特征图在对应的信道上做乘法运算==。==FPN使用的是Eltw Sum（也叫broadcast add）操作，将浅层和深层的特征图在对应的信道上做加法运算==。

![img](https://pic3.zhimg.com/80/v2-ffdce561798f4fea27ae0951b2d431be_hd.jpg)

![img](https://pic4.zhimg.com/80/v2-ee9f16715932756f9a62aa0d5eb24b07_hd.jpg)

![img](https://pic3.zhimg.com/80/v2-fc4a570ed21c436b2218d72c500be63e_hd.jpg)

## 二、网络结构设计

**1. 总体结构**

DSSD的网络结构与SSD对比如下图所示，以输入图像尺寸为为例，图中的上半部分为SSD-resnet101的网络结构，conv3_x层和conv5_x层为原来的resnet101中的卷积层，后面的五层是SSD扩展卷积层，原来的SSD算法是将这七层的特征图直接输入到预测阶段做框的回归任务和分类任务。DSSD是将这七层特征图拿出六层（去掉尺寸为的特征图）输入到反卷积模型里，输出修正的特征图金字塔，形成一个由特征图组成的沙漏结构。最后经预测模块输入给框回归任务和分类任务做预测。

![img](https://pic2.zhimg.com/80/v2-6ae2a6f58bba3228aaf8018d406af5a5_hd.jpg)

**2. 反卷积模型**

所谓反卷积模型指的是DSSD中高层特征和低层特征的融合模块，其基本结构如下图所示：

![img](https://pic2.zhimg.com/80/v2-b292b9f8f921dd90860967b662183979_hd.jpg)

高层的特征图的尺寸为$2H*2W*D$，低层将要反卷积的特征图尺寸为$H*W*512$，这里有几点注意事项：

1) ==高层特征图的通道数将会被舍弃，在反卷积模型中，所有卷积和反卷积操作，卷积个数都依赖于输入的低层特征图的通道数==。

2) ==BN操作放在卷积层和激活层之间==。

3) ==之前一些方法的上采样都是通过双线性插值来实现的，DSSD是通过反卷积层来学习得到的上采样特征图==（**注：本条是根据原论文描述得来，具体实现过程中存在一定问题，会在下文中详细描述**）。

4) 高层特征图与低层特征图在通道融合的时候，使用了broadcast mul，DSSD作者也使用过broadcast add，结果发现通道之间相乘比相加可以提升0.2%个map，但是推理速度像素相加要略快于相乘。

5）在SSD中==一些网络如（vgg）的低层特征图需要增加normalization的操作处理==，因为 它的feature scale和其他层不同，如果混在一起训练，在实践过程中会很难训练（容易训飞），具体原理详见Liu Wei另外一篇论文 ICLR 2016, ParseNet:Looking wider to see better 。在DSSD进行高低层特征融合时同样要注意这个问题，低层特征必要的时候需要增normalization处理。

**3. 预测模型**

预测模型是在框回归任务、分类任务之前和反卷积模型之后添加的网络结构。

![img](https://pic1.zhimg.com/80/v2-28ba375b68edc5d925764863c0d038c4_hd.jpg)

预测模型结构如上图所示，(a)为SSD使用的方法，直接提取出网络中的多尺度特征图做分类和框回归的预测；(b)为是resnet残差单元的网络结构；==(c)为作者改进的只含一个残差单元的预测模型，在残差旁路将原来的特征图用的卷积核做处理后与网络主干道的特征图做通道间加法==；(d)为只含两个残差单元的预测模型。

在训练阶段，DSSD作者使用两段训练方法（详见下文），对比了上图四种预测方式的实验结果，最后确定采用结果(c)。因此在预测阶段，作者使用的是(c)的方式来对特征图做的处理。

## 三、模型训练方法

**1.** **SSD的default box的优化方式**

实验时，使用SSD模型初始化 DSSD网络，但是对于default box选取的长宽比例，作者在论文中做了详细的分析和改进。为了得到PASCAL VOC 2007和2012 trainval图片里各个物体对应的真实位置框的长宽比例，==作者用K-means对这些真是框内区域面积的平方根作为特征做了一个聚类分析，做聚类的时候增加聚类的个数来提升聚类的准确度==，最后确定七类的时候收敛的错误率最低如下图所示：

![img](https://pic1.zhimg.com/80/v2-a85d5725e87c00ab72f3e51b9dbc045c_hd.jpg)

因为SSD训练时使用的训练图片会重新调整比例变成方形的尺寸如()或者，但是在大多数的训练图片都是比较宽的图片，所以相应的真实框的宽度会变小一点。通过这种聚类实验最后确定了预测使用的default box的长宽比例为1、1.6、2和3，作为每一个特征图的default box所使用的长宽比例。

**2.** **DSSD训练方法**

DSSD作者在caffe的框架中将SSD的基础网络改成resnet101然后重新训练了一个新的SSD模型，以VOC的数据集为例，训练集使用的数据是VOC2007和VOC2012的trainval数据集，测试用的是07的测试集，训练时一共迭代了70k次，使用学习率为1e-3在前40k次iterations，然后调整学习率为1e-4、1e-5再分别训练20k次、10k次iterations。然后用用训练好的SSD模型来初始化DSSD网络。训练DSSD的过程分为两个阶段，第一个阶段，加载SSD模型初始化DSSD网络，并冻结SSD网络的参数，然后只增加反卷积模型(不添加预测模型)，在这样的条件下只训练反卷积模型，设置学习率为1e-3、1e-4分别迭代20k次和10k次；第二个阶段，fine-tune第一阶段的模型，解冻第一阶段训练时候冻结的所有参数，并添加预测模型，设置学习率为1e-3、1e-4再分别训练20k次、20k次iterations。

**注：我们的实验结果表明上述两阶段训练方法并没有得到提升，反而不冻结网络参数，直接训练网络效果更好，比原版SSD提升更多。具体见实验结果部分。**

**3.** **网络结构配置策略**

此方法主要是来验证反卷积模块和预测模型对于检测性能的作用，作者先是训练了一个输入图像为321*321的resnet101-SSD模型，它的map为76.4%。再加入了不同的预测模型结构((b)(c)(d)这三种，使用之后的map分别为76.9%,77.1%,77.0%) 以后效果确实变好了，作者发现预测模型(c)的map是最高的，所以确定并选取只含一层残差单元的模型结构来做候选框回归和分类任务，并在之后的输入为512的DSSD模型中，无论是训练VOC的数据集还是coco的数据集，都使用预测模型(c)来做实验。最后又fine-tune整个模型训练反卷积模型来讨论反卷积模型中特征图通道融合是使用相加还是相乘的效果好，实验结果如下图所示，可以看出信道相乘稍微好一些。图中最后一行为使用approximate bilinear pooling的结果。

![img](https://pic2.zhimg.com/80/v2-ecb3bb69f5745e4acc20f386c8a5063d_hd.jpg)

## 四、本文复现结果

我们在MXNet上实现了DSSD算法，同时在SSD网络基础上添加了Beyond Skip Connections: Top-Down Modulation for Object Detection中TDM模块，对比了DSSD和SSD+TMD的检测效果。算法实现过程中，为了实用价值，确保推理速度，我们对原文提出的网络进行了适当的改进，具体细节如下。

**1. 算法复现细节**

本文采用的DSSD论文中的设置：

- 在原始版本SSD中vgg16的conv4_3需要使用L2正则化来处理，因为这一层的梯度过大，容易引起loss=NAN，导致模型不能收敛。
- DSSD作者建议==推理阶段合并BN层到conv层==，公式如下所示，即将BN层合并到相邻的卷积层，可以加快计算速度1.2-1.5倍，这个设置本文没有验证，后续会实现。

![img](https://pic3.zhimg.com/80/v2-afdaa394080f1224a821c1a8ab42109e_hd.jpg)

本文改动设置：

- ==DSSD网络中以resnet101为基础的网络最低层预测层以及之后延伸出去的预测层通道数均为非常臃肿的1024，这样虽然map很高，但是网络速度非常慢模型大小也到了惊人的**1.5G**以上==。我们在实现过程中主要是基于实用性的考虑没有把网络变得这么重，而将六层特征图的通道数改为[1024,2048,512,256,256,128]，这样做的主要意义在于验证算法的普适性，观察该算法在其他参数甚至其它网络下是否同样有效。在使用vgg16网络时，七层特征图的通道数采用[512, 1024, 512, 256,256, 256, 256]。同时我们没有设置DSSD的default box的长宽比，仍然使用SSD的长宽比，并且减少了一些[3,1./3]的比例。
- ==DSSD文中在特征融合时将上采样替换成了反卷积。==我们为了对比反卷积是否对算法起到了正向作用，采用了另外两种top-down结构中所用到的上采样方法，即FPN: Feature Pyramid Networks for Object Detection和Beyond Skip Connections: Top-Down Modulation for Object Detection 采用的都是最临近插值法。
- 我们将Beyond Skip Connections文中的TDM模块加到SSD网络中，作为DSSD的对比。Beyond Skip Connections论文中所提到的方法是在faster rcnn网络中实现的，这里我们将它的“调制”的思想实现到SSD中，即SSD+TMD。同时，SSD+TMD中采用的上采样方法也是FPN和TDM中采用的最邻近差值法。

训练参数设置：

- 训练共迭代240个epoch，每80个epoch学习率衰减10倍，初始学习率设为2e-3，其他超参数设置和SSD一致。

**2. 实验结果**

本实验没有采用论文里面最重的网络，而是为了实用性，对网络设置进行了适当改进（见算法复现细节）。本实验的意义主要在于去验证论文算法思想的有效性，并非复现论文中提到的map，因此以下结果在voc2007 test 数据中的map值比原论文中提到的map要低。

![img](https://pic1.zhimg.com/80/v2-f016149a0998e7adc6786480ea069d14_hd.jpg)

其中：

- SSD_min_loss为初始化DSSD模型训练所使用SSD模型，选取的是模型训练loss最小情况下对应的SSD模型。
- DSSD*为使用SSD初始化网络，但是不冻结SSD参数得到的DSSD模型。
- DSSD_stage1为采用论文训练方法的第一阶段训练，冻结SSD所有参数，添加反卷积结构训练得到的模型。
- DSSD_stage2为采用论文训练方法的第二阶段训练，解冻第一阶段的参数并添加预测模型结构得到的模型。
- DSSD+TDM为将google TDM模块应用于SSD网络得到的模型，使用 imagenet模型初始化。

==**3. 结论**==

相比SSD，DSSD算法确实可以带来提升，但是本文验证结果表明，以下几点和论文结论不符。

a) 论文中提到SSD＋resnet101+321效果不如SSD+vgg16+300好，但我们的实验结果显示SSD＋resnet101+321 结果更好。但是DSSD＋resnet101+321的结果不如 DSSD+vgg16+300的结果好。

b) 论文中采用两阶段训练，我们严格按照论文参数进行训练，得到提升很有限，而且训练十分耗时。后来我们采用不冻结参数，直接训练，该方法得到的提升要高于原文中的两阶段训练法。时间也要快将近三倍。

c) 我们同时对比了Beyond Skip Connections: Top-Down Modulation for Object Detection一文中的TDM结构。发现vgg上提升效果要高于论文中的反卷积模块的效果，且训练速度和显存使用都要优于DSSD。

此外， 我们的实验结果表明，Backbone网络为vgg16-512时，Google TDM结合在SSD上的效果优于DSSD。

 