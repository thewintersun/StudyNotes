**均值：**![img](https://images2015.cnblogs.com/blog/310680/201604/310680-20160426134521845-61600162.png)

**方差**：![img](https://images2015.cnblogs.com/blog/310680/201604/310680-20160426134941330-2099994297.png)

**标准差**：![img](https://images2015.cnblogs.com/blog/310680/201604/310680-20160426135217173-203116377.png)

**协方差及其意义**

标准差和方差一般是用来描述一维数据的，但现实生活中我们常常会遇到含有多维数据的数据集，最简单的是大家上学时免不了要统计多个学科的考试成绩。面对这样的数据集，我们当然可以按照每一维独立的计算其方差，但是通常我们还想了解更多，*比如，一个男孩子的猥琐程度跟他受女孩子的欢迎程度是否存在一些联系。*

==协方差就是这样一种用来度量两个随机变量关系的统计量==，我们可以仿照方差的定义：

![1562118755672](D:\Notes\raw_images\1562118755672.png)

来度量各个维度偏离其均值的程度，协方差可以这样来定义：

![1562118773817](D:\Notes\raw_images\1562118773817.png)

协方差的结果有什么意义呢？==如果结果为正值，则说明两者是正相关的==（从协方差可以引出“相关系数”的定义），也就是说一个人越猥琐越受女孩欢迎。==如果结果为负值， 就说明两者是负相关==，越猥琐女孩子越讨厌。==如果为0，则两者之间没有关系==，猥琐不猥琐和女孩子喜不喜欢之间没有关联，就是统计上说的“相互独立”。

从协方差的定义上我们也可以看出一些显而易见的性质，如：

![1562118902097](D:\Notes\raw_images\1562118902097.png)

**三、协方差矩阵**

前面提到的猥琐和受欢迎的问题是典型的二维问题，而协方差也只能处理二维问题，那维数多了自然就需要计算多个协方差，比如n维的数据集就需要计算![1562118947439](D:\Notes\raw_images\1562118947439.png)个协方差，那自然而然我们会想到使用矩阵来组织这些数据。给出协方差矩阵的定义：

![1562118968023](D:\Notes\raw_images\1562118968023.png)

这个定义还是很容易理解的，我们可以举一个三维的例子，假设数据集有三个维度，则协方差矩阵为：

![1562118988204](D:\Notes\raw_images\1562118988204.png)

可见，协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。
