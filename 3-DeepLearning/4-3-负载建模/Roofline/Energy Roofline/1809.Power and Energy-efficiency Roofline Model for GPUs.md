## Power and Energy-efficiency Roofline Model for GPUs

地址：https://arxiv.org/abs/1809.09206

作者：Millad Ghane, Jeff Larkin, Larry Shi, Sunita Chandrasekaran, Margaret S. Cheung

机构：NVIDIA；University of Delaware, Newark；University of Houston, Houston



### 摘要

近年来，能源消耗一直备受关注，开发人员在设计算法时需要考虑能源效率。他们的设计需要节能且低功耗，同时要努力实现底层硬件提供的可达到的性能。但是，不同的优化技术对功率和能量效率的影响不同，视觉模型将有助于选择过程。
在本文中，我们扩展了Roofline模型并提供了==功耗优化策略的直观表示==。我们的模型由关于模型中包含的每种策略的各种上限组成。介绍了一种用于计算性能的Roofline模型和一种用于内存性能的Roofline模型。我们基于一些优化策略为NVIDIA的两个广泛使用的GPU组装了模型：Geforce GTX 970和Tesla K80。



### 介绍

本文的主要目的是在单个模型中直观地演示三个支柱之间的关系：==性能，功耗和内核能效==，以便为开发人员提供有洞察力的信息。本文的贡献如下：

- 直观的视觉表示：我们的模型提供了关于系统能源消耗的直观的视觉表示。考虑到功耗以及计算和内存的效率，我们确定内核是受功耗限制（耗电）还是受计算限制。

- 能源效率：为了表征我们的体系结构的效率，我们将能源效率定义为flops per Joule (J)。我们在模型中证明了能效和功耗之间的权衡。

- 优化技术对功率和能量效率的影响：通过我们的模型，开发人员可以了解优化技术将如何影响功率和能量效率，以及哪种技术对我们的内核有更大的影响。

对于简单的冯·诺依曼架构[6]，能耗建模为：

![1614240212194](D:\Notes\raw_images\1614240212194.png)

其中==$E_ {flops} $和$ E_ {mem} $分别代表浮点计算和内存操作的总能耗。 $E_0$ 是系统工作所需的恒定能量==。我们的假设 $E_0$ 在执行期间保持恒定。 

![1614240437604](D:\Notes\raw_images\1614240437604.png)

![1614241576526](D:\Notes\raw_images\1614241576526.png)

![1614241692039](D:\Notes\raw_images\1614241692039.png)

![1614241759981](D:\Notes\raw_images\1614241759981.png)
$$
\begin{align}
P & = \frac W t \epsilon_{flop} + \frac Q t \epsilon_{mem} \\
& =  \frac W t *(\epsilon_{flop} + \frac Q W \epsilon_{mem}) \\
& = \frac W t * E_W 
\end{align}
$$
![1614241817980](D:\Notes\raw_images\1614241817980.png)

![1614241837194](D:\Notes\raw_images\1614241837194.png)

![1614243432526](D:\Notes\raw_images\1614243432526.png)

衡量HPC系统中能量效率的常用指标是 performance-per-watts，其中性能定义为每秒“有用的工作”。在科学计算中，工作以算术运算的数量来衡量，而在图遍历算法中，可以定义为图中遍历的节点数[6]。因此，在本文中，计算能效定义为以下等式：

![1614243561057](D:\Notes\raw_images\1614243561057.png)

![1614244175382](D:\Notes\raw_images\1614244175382.png)

我们的模型==提供了Power和EE的上限==。这将帮助开发人员了解可以减少功耗和或提高内核EE的优化。换句话说，如果要执行一个内核以收集其功率和EE级别，我们的模型旨在确定应实现的优化，使该内核消耗更少的功率和或提高能源效率。==每种优化技术在我们的模型中均表示为上限，用于指定应用该技术的效果==。两个连续的上限之间的幂和EE差距将显示通过启用关联技术将获得多少收益或损失。

图1描绘了NVIDIA Geforce GTX 970的单精度和双精度计算的计算和内存顶线模型。为研究计算性能的影响，我们在CUDA中实现了一个简单的约简内核，该内核可计算dot product of two big arrays（每个都有67,108,864个元素）。

- 首先，我们更改了线程和块的数量。在以下附图中，它们表示为$t \times b$个数字的集合，其中t和b分别表示一个块中的线程数和块数。 图1证明，==增加线程总数会导致单精度计算损失几瓦特，从而使内核更节能==。当块的数量增加到一个数量级时，此声明也是正确的，否则，它对EE没有帮助。同样的趋势对于双精度计算也很明显。
- 下一步，我们研究了启用融合乘加（FMA）操作的效果。 ==FMA上限表示此优化，而线程和块的数量设置为其峰值（1x32）。图1显示了启用FMA对功耗和EE没有明显影响==。  
- 最后一步是通过展开和维护主循环的部分和来研究指令级并行性（ILP）的效果。对于单精度计算，可以很容易地发现这种优化的效果。在这两种精度情况下，==启用ILP无疑都可以增强EE，同时仅消耗少量额外的瓦特==。
- 以上案例显示了FMA和ILP技术相互独立研究的结果（FMA + ILP）。但是，我们==同时启用了它们并调查了它们的效果。像我们以前的理解一样，FMA的操作并没有显着影响性能和能耗==。

![1614244236699](D:\Notes\raw_images\1614244236699.png)

图1描绘了这些对GTX 970的影响。与将内存访问限制为总线程的一小部分相比，==交错式内存访问对EE具有显着影响==。

- 如果50％的线程以跨步方式访问内存，则我们内核的EE将急剧下降。==这表示如果内核超出此上限，则开发人员需要研究对内存的不必要的跨步访问，以找出内核中丢失EE的来源==。
- 另外，由于双精度计算所需的带宽几乎是单精度计算的两倍，==因此thread abandonment的影响可能与跨步访问一样严重==。Normal 是指系统中所有线程之间的统一内存访问。

![1614412706837](D:\Notes\raw_images\1614412706837.png)


图2显示了我们用于NVIDIA Tesla K80的模型。它描述了==提高能耗效率的唯一方法是实施ILP或启用FMA操作==。

线程和块数量的增加导致消耗更多的功率，同时却==没有提高能源消耗的效率==。当块数增加一个数量级时，我们会观察到一些EE，否则，就像在GTX 970中一样，以小步长增加块数对EE没有帮助。

在我们的设计中，应该启用所有级别的并行性以实现能源效率。 K80的内存上限遵循与GTX 970类似的方法。设备上的交叉内存访问大大降低了我们获得EE的机会。但是，当我们执行双精度操作时，从线程子集发出内存访问（而不是对设备内存的统一访问）会对EE产生不利影响。

**我们的模型如何帮助开发人员？**我们用 energy per flop 和 energy per byte 表示一个给定内核的计算和内存性能来表示一个内核。这些点相对于我们模型中的上限的位置将帮助开发人员确定相关的优化技术，以提高内核的功能和EE。通过为我们启用的每种技术浪费几瓦的功率，可以从视觉上识别出我们的系统有多少能源效率。例如，如果对于K80的双精度计算，内核的数据点落在1x1的上限以下，则表明我们要么需要在内核中实施ILP优化技术，要么将并行度提高到其可达到的峰值。

应该注意的是，我们的模型代表了功耗与EE之间的关系。尽管我们的模型没有为开发人员确定优化技术（而屋面线模型可以确定），但是我们的模型有助于理解优化对功率和能源效率的影响。不过，可以确认我们图中的线（坡度）的陡度与计算性能（FLOP / s）和存储性能（BW）有关；在我们的图1和图2中，靠近Y轴的天花板代表了更好的性能。

