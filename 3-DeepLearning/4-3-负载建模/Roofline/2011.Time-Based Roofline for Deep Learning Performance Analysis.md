## Time-Based Roofline for Deep Learning Performance Analysis

论文地址：https://arxiv.org/abs/2009.04598

作者：Yunsong Wang, Charlene Yang, Steven Farrell, Yan Zhang, Thorsten Kurth, Samuel Williams

机构：Lawrence Berkeley National Laboratory

发表：Deep Learning on Supercomputing (DLonSC)

时间：November 2020



### 摘要

深度学习应用通常是非常计算密集的, 需要长时间的训练和推理。这是由硬件和软件方面的研究人员共同来解决的, 在本文中, 我们提出了一种基于Roofline-based的性能分析方法, 以方便这些应用程序的优化。

这种方法是在传统高性能计算应用程序中广泛应用的Roofline模型的扩展, 它==结合了计算/带宽的复杂性与运行时间, 在其公式中, 以提供深度学习的特性==。 it incorporates both compute/bandwidth complexity and run time in its formulae。

我们采用两组代表性内核, 2D Convolution 和LSTM, 来验证并演示了这种新方法的使用, 并研究了算术强度（arithmetic intensity）、cache locality、自动调优（auto-tuning）、内核启动开销（kernel launch overhead）以及 Tensor Core usage 是如何影响性能。

与常用的方法相比, 这项研究有助于形成一种更系统的方法来分析代码性能, 并识别深度学习应用程序的优化机会。

**总结：**针对深度学习特征，采用Roofline的改进版本进行应用程序的分析，在公式中加入了RunTime的信息。

### 介绍

到目前为止，大多数==性能分析都只集中在运行时间（run time）上==，而对于不同的网络、算法、框架如何利用不同的硬件功能（例如针对不同数据精度、各种缓存级别上的内存带宽等计算功能）的了解却很少。

在本文中，我们==扩展了传统的Roofline模型，将计算/带宽复杂度和运行时间都纳入了模型==，并为深度学习应用程序的性能分析提供了更全面，更深入的方法。在本文的其余部分中，我们将利用这种方法来分析用PyTorch，TensorFlow v1和TensorFlow v2编写的精度和参数的变化的Conv2D和LSTM内核。

### METHODOLOGY

![1611730916961](D:\Notes\raw_images\1611730916961.png)

![1611730931196](D:\Notes\raw_images\1611730931196.png)

图2：扩展Roofline模型以合并时间和复杂性。 （a）传统Roofline，（b）计算带宽复杂度，（c）计算和带宽时间，（d）4D复杂度-时间Roofline。请注意，所有图均以对数-对数比例表示。

**A. Roofline Model**

通过构造，将Roofline边界定义为峰值性能或算术强度与峰值带宽的乘积中的最小值：

![1611731155348](D:\Notes\raw_images\1611731155348.png)

**B. Computational and Bandwidth Complexity**

传统上，计算复杂度（Big O表示法）已用于通过==计算操作数==来分析不同的算法。这些方法中的每一种都有非常不同的计算复杂度。不幸的是，如Roofline所示，仅计算FLOP不足以分析性能。为此，我们通过==带宽复杂性==来增加计算复杂性。执行算法需要多少数据更新（Bytes）的度量。

图2（b）显示我们可以为算法复杂度创建一个新模型。轴定义为算法的计算和带宽复杂度。==恒定算术强度的等值曲线是穿过结果平面的对角线==，其机器平衡度表示特定于体系结构的算术强度，其中计算开始主导数据移动。我们可以类似地定义一个框（复杂度小于峰值性能和总开销的乘积），其中GPU内核启动开销主导着数据移动和计算。像在Roofline中一样，我们可以计算2D复杂度平面中的内核计算和带宽复杂度以及散点图性能。==靠近原点的内核执行的工作很少，而远离原点的内核具有很高的复杂性==。

请注意，如果算法需要更多的GPU内核启动或备用架构具有更高的开销，则开销限制区域可能会增加。同样，通过使用张量核心来提高峰值性能，会==将机器平衡对角线（从带宽到计算边界的转换）移到更高的算术强度==。

**C. Compute and Bandwidth Time**

本文的主要见解是，我们==可以将计算带宽复杂度坐标系重新映射为2D时间坐标系：计算时间和带宽时间==。

本质上，如果内核在复杂度平面中受计算限制compute-bound，则我们将其==计算时间定义为内核的运行时间==，并将其带宽时间定义为其==运行时间按算术强度与机器平衡之比==（2）（ 3）。

相反，如果内核是内存受限 memory-bound 的，则将其带宽时间定义为运行时间，并将其计算时间定义为运行时间，该运行时间按机器平衡与算术强度的比值进行缩减。

隐式地，我们==假设较小的时间可以与较大的时间完美重叠==（即计算时间可以与带宽时间重叠）。

![1611732804035](D:\Notes\raw_images\1611732804035.png)

**D. 4D Complexity-Time Roofline**

最终，我们可以将复杂性和时间组合成一个4维图形。图2（d）显示，不是尝试在2D纸上绘制4D tesseract，对于每个内核，我们使用主轴上的闭合符号绘制前两个坐标（计算和带宽复杂度），第二个两个坐标（计算和存储时间），在辅助轴上使用一个打开的符号（每个内核有两个符号）。通过按峰值GFLOP/s和峰值GB/s缩放计算和带宽时间，我们可以立即评估==数据局部性（算术强度），算法效率（复杂性）和运行时间（计算/带宽时间）==。

此外，打开（实际运行时间）符号与关闭（复杂度）符号的接近度使我们能够评估性能（与Roofline的距离）。其符号==被广泛分隔的内核明显不如其Roofline约束。符号接近的内核可以达到接近Roofline峰值性能的水平==。

### EXPERIMENTAL SETUP

硬件：Intel Xeon Gold 6148 Skylake CPUs,  384 GiB DDR4 memory, 8 NVIDIA V100 GPUs

软件：CUDA 10.2.89, cuDNN 7.6.5, Nsight Compute 2019.5.0, Python 3.7, PyTorch GPU 1.5.0, TensorFlow GPU 1.15.0 (TF1), and TensorFlow GPU 2.2.0 (TF2)

测试对象：2D Convolution Resnet50 ， LSTM Cell 

我们已经在三个不同的框架PyTorch，TF1和TF2中实现了这些内核，并且将针对相同框架和精度格式（FP32或FP16）的结果显示趋势线或轨迹线。

### RESULTS

实线连接实线符号以表示计算和带宽的复杂性，虚线连接空心符号以显示运行时间。

分析结果为计算内核的20多次迭代的平均值。

![1611740509416](D:\Notes\raw_images\1611740509416.png)
图3：通过更改Conv2D内核中的==批处理大小来提高性能==。两个TensorFlow框架倾向于使用相同的基础算法，并提供非常相似的运行时性能。 PyTorch以半精度和单精度呈现相同的带宽复杂度，建议使用隐式类型转换机制。

**1)  Batch Size:** 图3显示了将batch size从16、32更改为64时基于时间的Roofline图表。在正向过程中，图3a和3b具体来说是==算术强度（AI ）对于每个框架（PyTorch，TF1或TF2）都会保留preserved，这表明无论批处理大小如何，都使用相同的基础算法==。 

从理论上讲，当从FP16切换到FP32时，预计数据移动会增加2倍-TF1和TF2会增加3倍，但是PyTorch的带宽复杂度几乎保持不变，这表明可能==存在自动类型转换机制来转换隐式降低数据精度以提高整体效率==。

![1611744273275](D:\Notes\raw_images\1611744273275.png)

不同框架之间的一个明显区别是内核调用的数量，这可以通过图3c中==开销框==的大小看出。TF2（绿色）比TF1（红色）具有更高的净启动开销，而PyTorch（蓝色）位于中间。 TF1和TF2之间的差异可能是由于TF2中Eigen函数的广泛使用导致了总体启动开销。就==内核运行时间而言，PyTorch优于TF1和TF2==，因为它用于数据填充，改组和重新排列的零AI内核少于TF1和TF2。在这三个框架中，==TF1是唯一在较小的批处理量下不使用Tensor Core运算的框架，从而降低了运算强度==。但是，随着批量大小的增加，其自动调整机制确实可以直接应用于Tensor Core实施。

![1611746342285](D:\Notes\raw_images\1611746342285.png)

**2) Number of Output Channels:**  在前向传递中，TF1和TF2的性能非常相似，因为它们的趋势线高度一致（图4）。我们发现，对于TF1和TF2，==更大数量的输出通道将导致更高的FLOP速率和更高的算术强度==。仅仅是因为内核比输入张量小得多，所以与增加存储更多通道的内存空间相比，额外通道带来的FLOP计数的增加意义重大。但是==相同的结论不能用于描述单精度PyTorch行为因为它性能很少改变，带宽复杂度与其计算复杂度成正比==。

在半精度中，所有三个框架的趋势线都非常相似，并且由于数据移动较少，TF2优于其他两个框架。我们发现三个框架使用相同的2D卷积内核，但是==PyTorch调用了额外的nchwToNhwcKernel函数来执行数据转置==。

![1611747152130](D:\Notes\raw_images\1611747152130.png)

根据滤波器的数量，精度和框架的不同，后向传播的性能差异很大（见图5）。

- 通常，TF1在这三个框架中具有最低的计算复杂度，并且与内核启动延迟无关。
- 半精确地说，我们可以得出结论，在==所有三个框架中选择算法似乎对输出通道的数量非常敏感，因为在这种情况下，它们永远不会为不同的参数重用同一组内核==。
- 最后，通过512个过滤器，所有三个框架中的内核都从memory-bound 转移到了compute-bound。
-  ==TF2提供最高的FLOP/ s性能和算术强度，并且还需要最长的运行时间==。

**3) Kernel Size:**


  ![1611747448527](D:\Notes\raw_images\1611747448527.png)

图6：经典的Roofline图强调了FLOP/s的性能，这不能被基于时间的Roofline反映出来。 ==PyTorch单精度FLOP/s的性能保持不变，这意味着它饱和了某些硬件资源== （蓝色线最后两个点水平）。因此，无论内核大小如何增加，性能都不会再增加。为了改善这种情况，应该研究使用替代卷积算法的可能性。

**4) Stride Size:**

对于相同的带宽复杂度，==stride 大小的增加表示较低的计算复杂度==，因为在计算期间会掩盖更多的输入数据。分析结果（参见图7）与预期一致，因为带宽复杂度与计算复杂度相比相对恒定。此外，应注意的是，==较低的计算复杂度并不一定意味着调用次数会减少，因此，当步幅大小增加时，内核就会变得开销更大==。

![1611747698513](D:\Notes\raw_images\1611747698513.png)

![1611747961801](D:\Notes\raw_images\1611747961801.png)

==在stride大小等于1的半精度中，PyTorch和TF2代码受compute-bound，而TF1受memory-bound==。此外，PyTorch和TF2的FLOP/s性能均高于TF1（图8）。此外，我们发现随着步幅的增大，TF1的性能会大大下降。原因是TF1倾向于使用非Tensor Core算法wgrad_alg0_engine，因为步幅大小等于2和3，其峰值性能仅为每秒5个TFLOP。与前向遍历相同，由于==对半精度数据使用单精度算法，因此TF2的步幅等于3时会降低性能==。
 **B. LSTM**

图9显示了使用四种不同的批处理大小（16、32、64和128）运行时LSTM的基于时间的Roofline。结果与卷积内核截然不同，并且==无论批处理大小和正/后向传递，计算始终受开销限制==。显然，较大的批处理量将带来更多的FLOP，==并且要执行的数据移动因此会带来计算复杂性的明显增加==。但是，由于内核本质上是开销受限的，因此对AI或FLOP/s性能的微不足道的改进。

![1611748333908](D:\Notes\raw_images\1611748333908.png)

图9：半精度LSTM向后传递中批次大小的性能影响。==不管我们如何改变批处理大小，内核总是受到开销的限制，并且运行时间保持不变==。 我们注意到，TF1和TF2调用的内核要比PyTorch的多得多，因为它们的开销框大于PyTorch的开销。

![1611748493960](D:\Notes\raw_images\1611748493960.png)

图10：LSTM中序列长度的性能影响。较长的序列长度意味着重复相同的计算更多次。==内核AI保持不变，运行时间与序列长度成正比==。


  