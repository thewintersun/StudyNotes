## Roofline: An Insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures

作者：Samuel Webb Williams，Andrew Waterman，David A. Patterson

机构：Electrical Engineering and Computer Sciences，University of California at Berkeley

论文地址：https://dl.acm.org/doi/10.1145/1498765.1498785



### ABSTRACT

We propose an easy-to-understand, visual performance model that offers insights to programmers and architects on improving parallel software and hardware for floating point computations.

我们提出了一个易于理解的、可视化的性能模型，为程序员和架构师提供了改进并行软件和硬件浮点计算的见解。

### INTRODUCTION

我们认为未来几年，==片外存储器的带宽==会成为资源的限制。因此，我们需要一个能将==处理器性能==与==片外存储器通信==联系起来的模型。

Towards that goal, we use the term ==operational intensity（操作强度）== to mean operations per byte of DRAM traffic.

$$
Operational\_Intensity = Operations / DRAM\_Traffic\_Bytes
$$
We define total bytes accessed as those that go to the main memory after they have been filtered by the cache hierarchy. That is, we ==measure traffic between the caches and memory== rather than ==between the processor and the caches==. Thus, operational intensity suggests the ==DRAM bandwidth needed== by a kernel on a particular computer.

我们将访问的总字节定义为经过缓存层次结构筛选后进入主存的字节数。也就是说，我们测量缓存和内存之间的流量，而不是处理器和缓存之间的流量。因此，操作强度暗示了指定计算机上内核所需的DRAM带宽。

提出的模型将（floating-point performance）浮点性能、（operational intensity）操作强度和（memory performance）内存性能结合在一个二维图中。

- 峰值浮点性能可以通过使用（hardware specifications）硬件规范或（microbenchmarks）微基准测试来找到。
- 我们这里所考虑的内核的工作集（working sets） 并不完全适合onchip caches，所以峰值内存性能（peak memory performance）是由 the memory system behind the caches 定义的。虽然您可以通过STREAM benchmark[22]找到内存性能，但为了完成这项工作，我们编写了一系列逐步优化的微基准测试，旨在确定可持续的DRAM带宽。它们包括获得最佳内存性能的所有技术，包括预取（prefetching ）和（data alignment）数据对齐。

![1609920570007](D:\Notes\raw_images\1609920570007.png)

Figure 1. Roofline Model for (a) AMD Opteron X2 on left and (b) Opteron X2 vs. Opteron X4 on right.

The graph is on a log-log scale. Y轴是可实现的浮点性能。X轴是操作强度，从访问1/4 Flops/DRAM字节到访问16 Flops/DRAM字节不等。在我们的基准测试中，所建模的系统具有17.6 GFlops/sec的峰值双精度浮点性能和15 GBytes/sec的峰值内存带宽。

This latter measure is the steady state bandwidth potential of the memory in a computer, not the pin bandwidth of the DRAM chips.这张图是对数对对数的。后者的测量是计算机中内存的稳态带宽潜力，而不是DRAM芯片的引脚带宽。

我们可以画一条水平线来显示计算机的峰值浮点性能。显然，浮点内核的实际浮点性能不能高于水平线，因为这是硬件限制。==我们如何绘制峰值内存性能?因为X轴是GFlops /字节,Y轴是GFlops/秒,字节每秒等于(GFlops / second)/(GFlops / byte)——这只是一个45度角的直线==。因此, 我们可以绘制第二个横线,  在给定的操作强度下，计算机的内存系统可以支持的最大的浮点性能。这两条线在峰值计算性能和峰值内存带宽处相交。

This formula drives the two performance limits in the graph in Figure 1a:
*==Attainable GFlops/sec = Min ( Peak Floating Point Performance, Peak Memory Bandwidth x Operational Intensity )==*

注意,对角线和水平屋顶相遇的山脊点, 提供对计算机整体性能的洞察。脊点的X坐标是实现最大性能所需的最小操作强度。 



### ADDING CEILINGS TO THE MODEL

Roofline模型为性能提供了一个上限。==假设您的程序的性能远低于它的上限。应该执行哪些优化，以及以什么顺序执行?== 绑定和瓶颈分析的另一个优点是：

> A number of alternatives can be treated together, with a single bounding analysis providing useful information about them all.
>
> 许多替代方案可以一起处理，一个边界分析就可以提供所有这些方案的有用信息。

我们利用这一洞察力==在Roofline模型中添加多个上限，以指导执行哪些优化==，这与loop balance提供给编译器的指导方针类似。我们可以将每一种优化都看作是低于（appropriate Roofline）适当上限的（performance ceiling）“性能上限”，这意味着如果不执行相关的优化，就无法突破上限。

例如，为了减少Opteron X2的**计算瓶颈，**有两个优化可以帮助几乎所有的内核 :

- 提高 ==指令级并行度( instruction level parallelism， ILP)== 和 应用 ==SIMD (Single Instruction Multiple Data,单指令多数据玲构)==。对于==超标量体系结构==，最高的性能来自于获取、执行和提交每个时钟周期的最大指令数。这里的目标是改进编译器中的代码以增加ILP。最高的性能来自于完全覆盖功能单元的时延。
  - ==一种方法是展开循环==。对于基于x86的架构，
  - 另一种方法是==尽可能使用浮点SIMD指令==，因为SIMD指令对相邻的操作数进行操作。
-  ==平衡浮点操作组合。== 最佳性能要求, 指令混合的一个重要部分（a significant fraction）是浮点操作(见第7节)。峰值浮点性能通常也需要==相同数量的（simultaneous ）同步浮点 additions 和 multiplications==, 因为许多计算机都有多个添加指令, 或者因为它们有相等数量的adders和multipliers。

为了减少**内存瓶颈**, 三个优化可以帮助:

- Restructure loops for unit stride accesses 重构单元程访问的循环. Optimizing for unit stride memory accesses engages hardware prefetching, which significantly increases memory bandwidth. 优化单元跨距内存访问使硬件预取（prefetching）变得更大, 这大大增加了内存带宽。
- Ensure memory affinity 确保内存亲和力。现在大多数微处理器都在同一个芯片上包含一个内存控制器。If the system has two multicore chips, then some addresses go to the DRAM local to one multicore chip and the rest must go over a chip interconnect to access the DRAM that is local to another chip.后一种情况会降低性能。这种优化将数据和处理该数据的线程分配到相同的内存-处理器对，这样处理器就很少需要访问其他芯片上的内存。
- Use software prefetching 使用软件预取。通常，最高的性能要求保持许多内存操作的运行，这更容易通过预取而不是等待数据被程序实际请求。在一些计算机上，软件预取比单独的硬件预取提供更多的带宽。

计算上限可以来自优化手册[2]，很容易从简单的微基准测试收集必要的参数。内存上限要求在每台计算机上进行实验，以确定它们之间的（gap）间隙。好消息是，就像屋顶线一样，==每个多核计算机只需要测量一次天花板==。

![1610010171952](D:\Notes\raw_images\1610010171952.png)

图2在图1a中的Roofline模型上增加了上限，图2a显示了计算上限，图2b显示了内存带宽上限。尽管较高的上限并没有标记为较低的优化，==但它们意味着:要突破一个上限，您需要已经突破了下面的所有上限==。图2a显示了如果浮点运算组合不平衡，计算“上限”为8.8GFlops/sec，如果增加ILP或SIMD的优化也没有得到，计算“上限”为2.2GFlops/sec。图2b显示了在不进行软件预取的情况下，内存带宽上限为11G字节/秒，在不进行内存亲和性优化的情况下，内存带宽上限为4.8G字节/秒，在只进行单元扩展优化的情况下，内存带宽上限为2.7G字节/秒。

图2c 将另外两个图形组合成一个图。图2c的中间是计算优化和内存带宽优化重叠区域。例如, 内核2落在右边的蓝色上, 它只在计算优化上工作。如果一个内核落在左下角的黄色三角形中, 模型将建议尝试仅仅是内存优化。内核1在中间的绿色(=黄色+蓝色)平行四边形, 这建议尝试两种类型的优化。

Roofline Model的天花板表明要执行哪些优化。==天花板与下一个更高的天花板之间的差距的高度是尝试这种优化的潜在奖励==。因此，图2表明，优化1(改进ILP/SIMD)对改进该计算机上的计算有很大的潜在好处，而优化4(改进内存亲和性)对改进该计算机上的内存带宽有很大的潜在好处。

