#### Dynamic Routing Between Capsules
- 论文地址：https://arxiv.org/abs/1710.09829 
- 作者： Geoffrey E. Hinton
- 机构： Google Brain
- 文章出处： https://zhuanlan.zhihu.com/p/29435406 



#### Hinton 反对CNN的理由

Hinton自己也承认，CNN做的非常好。但是当Hinton做了一系列认知神经科学的试验后，HInton 觉得有些动摇，直至他现在反对CNN。
最简单的手相性就是分清左右，这个到现在很多人都会搞混。判断手相性对人来说是很困难的。Hinton 给的例子是“意识旋转”(mental rotation)，这个问题是判断某两个图形的手相性是否一致:

![1565866951204](D:\Notes\raw_images\1565866951204.png)

我们无法直接回答，而是要在意识中“旋转”某个R，才能判断手相性是否一致。并且角度差的越大，人判断时间就越长。
而“意识旋转”同样突出了“坐标框架”的存在，我们难以判断手相性，是因为它们有不一致的坐标框架，我们需要通过旋转把坐标框架变得一致，才能从直觉上知道它们是否一致。

通过这几个实验，Hinton得出了这样的结论：
==人的视觉系统会建立“坐标框架”，并且坐标框架的不同会极大地改变人的认知。==

也就是人识别物体的时候，坐标框架是参与到识别过程中的，识别过程受到了空间概念的支配，并不是独立的过程。“坐标框架”在此处就是人的一种“先验知识”。但是在CNN上却很难看到类似“坐标框架”的东西。

Hinton 提出了一个猜想：
物体和观察者之间的关系（比如物体的姿态），应该由一整套激活的神经元表示，而不是由单个神经元，或者一组粗编码（coarse-coded，这里意思是指类似一层中，并没有经过精细组织）的神经元表示。只有这样的表示，才能有效表达关于“坐标框架”的先验知识。
而这一整套神经元，Hinton认为就是Capsule。

**同变性（Equivariance）和不变性（Invariance）**

Hinton 反对 CNN的另外一个理由是，CNN的目标不正确。问题主要集中在 Pooling 方面（我认为可以推广到下采样，因为现在很多CNN用卷积下采样代替Pooling层）。Hinton认为，过去人们对Pooling的看法是能够带来 invariance 的效果，也就是当内容发生很小的变化的时候（以及一些平移旋转），CNN 仍然能够稳定识别对应内容。
但是这个目标并不正确，因为最终我们理想的目标不是为了“识别率”，而是为了得到对内容的良好的表示(representation)。如果我们找到了对内容的良好表示，那么就等于我们“理解”了内容，因为这些内容可以被用来识别，用来进行语义分析，用来构建抽象逻辑，等等。而现在的 CNN 却一味地追求识别率，这不是Hinton想要的东西。
Hinton的看法是，我们需要 Equivariance 而不是 Invariance。
所谓 Invariance，是指表示不随变换变化，比如分类结果等等。

![1565867020025](D:\Notes\raw_images\1565867020025.png)

Invariance 主要是通过 Pooling 等下采样过程得到的。如果你对训练神经网络有经验，你可能会想到我们在做图像预处理和数据拓增的时候，会把某些图片旋转一些角度，作为新的样本，给神经网络识别。

> 这样CNN能够做到对旋转的 invariance，并且是“直觉上”的invariance，根本不需要像人那样去旋转图片，它直接就“忽视”了旋转，因为我们希望它对旋转invariance。

CNN同样强调对空间的 invariance，也就是对物体的平移之类的不敏感（物体不同的位置不影响它的识别）。这当然极大地提高了识别正确率，但是对于移动的数据（比如视频），或者我们需要检测物体具体的位置的时候，CNN本身很难做，需要一些滑动窗口，或者R-CNN之类的方法，这些方法很反常（几乎肯定在生物学中不存在对应结构），而且极难解释为什么大脑在识别静态图像和观察运动场景等差异很大的视觉功能时，几乎使用同一套视觉系统。

对平移和旋转的 invariance，其实是丢弃了“坐标框架”，Hinton认为这是CNN不能反映“坐标框架”的重要原因。而 equivariance 不会丢失这些信息，它只是对内容的一种变换：

Hinton 认为 CNN 前面非 Pooling 的部分做的很好，因为它们是 equivariance 的。那么在 Capsule 的框架下，又应该如何体现 equivariance 呢？

Hinton 认为存在两种 equivariance：

- 位置编码（place-coded）：视觉中的内容的位置发生了较大变化，则会由不同的 Capsule 表示其内容。
- 速率编码（rate-coded）：视觉中的内容为位置发生了较小的变化，则会由相同的 Capsule 表示其内容，但是内容有所改变。

并且，两者的联系是，高层的 capsule 有更广的域 (domain)，所以低层的 place-coded 信息到高层会变成 rate-coded。
这里Hinton虽然没有指明，但是我感觉到 Hinton 是希望能够统一静态视觉和动态视觉的（通过两种编码方式，同时感知运动和内容）。人脑中对于静态和动态内容的处理通路并没有特别大的变化，但是现在做视频理解的框架和做图片理解的差异还是不小的。

但是，毕竟 invariance 是存在的，比如我们对物体的识别确实不和物体的位置有关。这里Hinton解释了一下：

> knowledge，but not activities have to be invariant of viewpoint

也就是Hinton谈论的问题是关于 activation 的，之前人们所说的CNN的 invariance 是关于神经元 activation 的。Hinton 希望 invariance 仅仅是对于 knowledge 的（对于Capsule而言，是其输出的概率部分；而其位置等参数是equivariant的）。通过这可以看到Hinton使用Capsule的一个原因是觉得Capsule相比单个神经元更适合用来做表示。

---

论文：Dynamic Routing Between Capsules
地址：https://arxiv.org/abs/1710.09829 
作者： Geoffrey E. Hinton
机构： Google Brain， Toronto
文章出处：https://www.zhihu.com/question/67287444/answer/251241736 

#### 摘要

胶囊意为一组神经元，其激活向量（activity vector）反映了某类特定实体（可能是整体也可能是部分）的实例参数（instantiation paramenters）。

本论文使用激活向量的模长来描述实体存在的概率，用激活向量的方向(orientation)表征对应实例的参数。
某一层级的活跃胶囊通过矩阵变换做出预测，预测结果会用来给更高层级的胶囊提供实例参数。当多个预测值达成一致时，一个高层级的胶囊就会被激活。

论文中展示了通过差异化训练的多层胶囊系统可以在MNIST上达到当前最高水平的表现，相比于比卷积网络，它在识别高度重叠的数字上要好得多。

网络的实现中运用an iterative routing-by-agreement mechanism：当低层级的胶囊的预测向量和高层级胶囊的激活向量有较大的标量积（scalar product）时，这个低层级胶囊就会倾向于向高层级胶囊输出。

本段引用：https://www.zhihu.com/question/67287444/answer/252315722

**用一组 Capsules 替代网络的一层**

Capsule 关键的一点是在于用复杂的 Capsule 替代现在神经网络中简单的 layer。

其重要理由之一是现在 layer 中的 neuron 太过简单，本身很难表征概念；而Capsule使用向量作为输入输出，而向量就可以作为良好的表征（比如word2vec中的向量就可以良好表征词汇），可以添加各种类型的实例参数（姿态，位置，大小，方向，变形，速度，颜色，反照率，纹理，等等）。

与一般的向量表征不同，Capsule 的输出向量表征了两个部分：

- 其长度表征了某个实例（物体，视觉概念或者它们的一部分）出现的概率。

- 其方向（长度无关部分）表征了物体的某些图形属性（位置，颜色，方向，形状等等）

用 Capsules 代替 layer 存在几个问题：

(1) 如何实现激活函数？

layer 使用了非线性函数来处理标量，而Capsule处理的是向量，那么又该用什么“激活函数”呢？ 答案是一个被称为 “squashing” 的非线性函数，（s为输入，v为输出，j为capsule的序号）
$$
\mathbf{v}_j={\|\mathbf{s}_j\|^2\over 1+\|\mathbf{s}_j\|^2} {\mathbf{s}_j \over \|\mathbf{s}_j\|}
$$
即
$$
\mathbf{v}_j={\|\mathbf{s}_j\|^2\over 1+\|\mathbf{s}_j\|^2} {\hat{\mathbf{s}_j}} ，

$$
其中 $\hat{\mathbf{s}_j } $是单位化向量，也就是缩放向量的长度为 ${\|\mathbf{s}_j\|^2\over 1+\|\mathbf{s}_j\|^2} $
它画出来如下：

![1565867243537](D:\Notes\raw_images\1565867243537.png)

这个函数的特点是：

- 值域在[0,1]之间，所以输出向量的长度可以表征某种概率。
- 函数单调增，所以“鼓励”原来较长的向量，而“压缩”原来较小的向量。
- 也就是 Capsule 的“激活函数” 实际上是对向量长度的一种压缩和重新分布。

(2) 如何处理输入？

layer 使用了矩阵，本质上是上层输出的线性组合。那么对于 Capsule 又应该怎么做呢？
Capsule 处理输入分为两个阶段：线性组合和routing。

线性组合一定程度上是借用layer中的线性组合的概念，不过这个线性组合不是针对 layer（也就是只有一个matrix），而是针对 capsules （一堆matrices），亦即: $\hat{\mathbf{u}}_{j|i}=\mathbf{W}_{ij}\mathbf{u}_i $

（其中u是下层的向量，由前层的标号为i的capsule产生，带帽子的u是处理后的结果，送给后层的标号为j的capsule）。这等于，原来NN中的“边权”（常量）变成了矩阵。

![1565867339366](D:\Notes\raw_images\1565867339366.png)

关于 routing 部分，其实是给 $\mathbf{\hat{u}}_{i|j} $加权求和，权重是 $\mathbf{c}_{ij} $。

![1565867354768](D:\Notes\raw_images\1565867354768.png)

而$ \mathbf{c}_{ij} $ 是 $\mathbf{b}_{ij} $ softmax 的结果，从而使得$ \mathbf{c}_{ij}  $分布归一化；并且由于softmax会使分布“尖锐化”，从而只有少数 $\mathbf{c}_{ij}$  有较大的取值，这样就起到了routing的作用（只有少数 $\mathbf{\hat{u}}_{i|j} $ 的权重较大，就好像底层的某个capsule的输出只贡献给上面的某个capsule）。

Routing 的更新：Updating by agreement

按照 Hinton 在很多视频中的理念，“找到最好的（处理）路径等价于（正确）处理了图像”。这也是 Capsule 框架中引入 Routing 的原因之一。而找到“最好路径”的方法之一就是找到最符合输出的输入向量。符合度通过输出向量和输入向量（线性变换后的向量）的内积所表征，这个符合度直接被加入到 $\mathbf{b}_{ij} $ 中。

![1565867423291](D:\Notes\raw_images\1565867423291.png)更新算法
![1565867444678](D:\Notes\raw_images\1565867444678.png)

这个更新算法很容易收敛。论文中认为3次足矣。routing 和其他算法一样也有过拟合的问题，虽然增加routing的迭代次数可以提高准确率，但是会增加泛化误差，所以不宜过多迭代。

![1565867464738](D:\Notes\raw_images\1565867464738.png)

#### 总结： capsule和传统神经元的对比

![1565867494041](D:\Notes\raw_images\1565867507791.png)

作者：云梦居客
链接：https://www.zhihu.com/question/67287444/answer/251460831

图中右边是传统神经元的模型，它接受来自上一层多个神经元的输出$x_{i}$(标量值)作为输入，对其进行加权、求和，然后进行sigmoid、ReLU等非线性操作，最后输出一个标量值；

左边就是capsule论文Sec2的几个公式，做一个对比，我们可以发现，capsule的输入是一个向量 $u_{i} $，输出 $v_{j} $也是一个向量，中间的公式Eq.1和Eq.2 就是从$u_{i}$到$u_{j}$的计算过程，这个过程可以一一地跟传统的神经元计算过程对应起来。

$u_{i}$到 $\hat{u}$ (Eq.2)是一个仿射变换，这是传统神经元所没有的操作，然后$\hat{u}$到 $s_{j}$ 是在 $c_{ij} $的加权下然后对 i 维度进行求和的操作，这个可以看作向量版的加权求和过程，再接着就是$ s_{j} $到 $v_{j}$，Eq. 1这个squashing函数是非线性的，而且输出的$v_{j}$保持了$s_{j}$的维度，所以可以看作是向量版激活函数。到了这里，我们可以看到，capsule就是一个向量版的神经元，所以可以叫它张量神经元，而不是所谓的“胶囊”。

#### 网络结构：CapsNet

![1565867753411](D:\Notes\raw_images\1565867753411.png)

这个实现用论文中使用mnist数据集进行实验，原始图片 28x28x1 首先使用ReLU Conv1(256个 9x9 核，步长为1)进行卷积操作，生成 20x20x256 feature maps。为了生成输入从标量变为8维的向量，使用 32个 9x9 核，步长为2 对上一个 feature maps进行卷积 8次，生成 32x6x6x8 (32个Capsules)。接着使用动态路由算法，最后经过一层全连接的隐藏层和Sigmoid层进行输出。

首先，来一个标准的CNN+ReLU。强迫症患者可能感到不是很舒服：为什么不全部使用Capsule，而是要来个CNN呢？

![1565867779435](D:\Notes\raw_images\1565867779435.png)

原因其实很简单，Capsule 的向量是用来表征某个物体的“实例”，并且按照假设，越高级的capsule能够表征更高级的实例。如果不通过CNN抽取特征，那么Capsule就直接得到图片的内容，这并不是很理想的低级特征。而浅层的CNN却擅长抽取低级特征，于是用CNN是在情理之中的。

> 这里注意到CNN的感知野很大（9*9，现在一般3*3），这是因为CNN层数很少的情况下，感知野越大，底层的capsules能够感知到的内容也越多。

但是，一层 CNN 的能力不足以抽取到合适的特征，于是这篇论文又加了一个 CNN层（一共32个CNN，文中称为32个channels，每个CNN有8个filters），这个 CNN 的输出构成了第一层 Capsules 的向量。
由于 CNN 共享权值的特点，这一层每个 CNN 输出的feature map中的36个capsules 是共享权值的（通过CNN）。显然所有的Capsules都共享权值是有问题的，这也是为什么这层搞32个CNN的道理：不同的 CNN 输出的Capsules间是独立的。

![1565867816317](D:\Notes\raw_images\1565867816317.png)

为了加深理解，我们可以对比一下CNN的输出和这层输出的Capsules的区别:

![1565867838697](D:\Notes\raw_images\1565867838697.png)

我们可以看到它们的相似点在于，每个”平面“内，变量都是共享权值的；而在不同”平面“内，变量是独立的。而不同点在于，在”平面“内CNN的单位是标量，而Capsules是一个capsule表征的向量。

这层的Capsules在论文中被称为 PrimaryCapsules ，这让我联想到 primary visual cortex（初级视皮层），因为如果说第一层卷积相当于视网膜，第二层卷积相当于初级视皮层，那么 PrimaryCapsules 的向量就是初级视皮层的表征。

第三层，也是输出层，就是一组10个标准的 Capsules，每个 capsule 代表一个数字。每个capsules 输出向量的元素个数为16。这组 Capsules 被称为 DigitCaps （取名逼死强迫症）。从 PrimaryCapsules 到 DigitCaps 使用了上文所述的 dynamic routing。这也是唯一使用dynamic routing 的地方。

![1565867872009](D:\Notes\raw_images\1565867872009.png)
按照假定，某个 capsule 输出向量的(范数)长度表示某个 capsule 表征的内容出现的概率，所以做分类的时候取输出向量的 L2 范数即可。

> 这里注意到，最后 capsules 输出的概率向量不是归一的，也就是 capsules 天然有同时识别多个物体的能力。

![1565867913047](D:\Notes\raw_images\1565867913047.png)

#### 优化

由于 capsules 允许多个分类同时存在，所以不能直接用传统的交叉熵损失，一种替代方案是 SVM 中常用的 margin loss：
$$
L_c = T_c\max(0, m^+− \|v_c\|)^2 + \lambda(1 − T_c)\max(0, \|v_c\| − m^−)^2
$$
其中 $c$ 是分类， $T_c$ 是分类的指示函数（分类c存在为1，否则为0），$ m^+$ 为上margin，惩罚假阴性（没有预测到存在的分类的情况）； $m^-$ 为下margin，惩罚假阳性（预测到不存在的分类的情况）。$ \lambda$ 是比例系数，调整两者比重。总的 loss 是各个$ L_c$ 之和。

至于优化算法，论文没有明说，其实不难猜到就是标准的反向传播（否则怎么搞CNN），估计作者觉得没有必要写了。

#### 重构与表示

Hinton 一直坚持的一个理念是，一个好的robust的模型，一定能够有重构的能力（”让模型说话“）。这点是有道理的，因为如果能够重构，我们至少知道模型有了一个好的表示，并且从重构结果中我们可以看出模型存在的问题。
之前我们说过，capsule 的一个重要假设是每个 capsule 的向量可以表征一个实例。怎么来检验这个假设呢？一个方法就是重构。
重构的时候，我们单独取出需要重构的向量，扔到后面的网络中重构。当然后面的重构网络需要训练。

![1565867990405](D:\Notes\raw_images\1565867990405.png)

但是有读者可能会有疑问：如何证明重构的好是因为Capsules输出了良好的表示，而不是因为后面的网络拟合的结果？我们知道哪怕前面的输入是随机的，由于神经网络强大的拟合能力，后面的网络也能拟合出重构结果。
一个证据是人为扰动 capsule 的输出向量。我们可以看到，如果逐渐改变向量的一些分量，表示也很有规律地改变，这是随机的输入难以做到的。

![1565868006753](D:\Notes\raw_images\1565868006753.png)

**重构与无监督学习**
论文中发现如果把重构误差计入，可以显著地提高准确率：

![1565868029063](D:\Notes\raw_images\1565868029063.png)
（其实很搞笑的是，这种提升远远大于对dynamic routing的调整）

需要注意到，重构是无监督的方式，不需要标签。如果重构能够大幅提升分类效果，那么就暗示了可以通过重构做无监督学习（重构也可能是人做无监督学习的途径之一）。这部分Hinton提了很多，应该已经做出来了，不过看样子不在这篇论文当中。

**重构与可解释性**
做capsule的动机之一还在于可解释性。我们需要看到NN为什么正确，为什么错误。这篇论文通过重构或多或少这一点，还是很有意思的。

比如下图左侧，都是分类正确的重构，可以看到重构除了还原本身外，还起到了去噪的效果。

右侧模型误把”5“识别成了”3“，通过重构，模型”告诉“我们，这是因为它认为正常的”5“的头是往右边伸出的，而给它的”5“是一个下面有缺口的”3“。

![1565868060589](D:\Notes\raw_images\1565868060589.png)
在识别重叠数字的时候，它显示了更强的重构能力，并且拒绝重构不存在的对象（右侧*号）

![1565868075784](D:\Notes\raw_images\1565868075784.png)

**为什么选择 MNIST 而不是 ImageNet**

我知道，大家都会吐槽为什么还要用 MNIST 这种用烂的数据集。
首先是，ImageNet 很难做重叠图像的实验（现实图片重叠的情况下本来就很难辨认，即使实现了也很难可视化），这点手写数字几乎是最理想的方案。
第二点是，在此实验的配置下，做 ImageNet 是自杀行为。因为 Capsules 假设是每个 Capsule 能够代表一个实例，本论文实现的动态路由方案比较naive，根本不能满足这么多的 Capsule 数量，何必做不符合自己假设的实验呢？其实文章作者知道这点，还是强行试了试 cifar10，果然效果不好（和最初应用到cifar10的CNN效果差不多）。

**全场最差：动态路由**

个人认为动态路由是论文中做的最不好的地方，做的太简单了，如果用论文中的动态路由方案，我想是无法做到训练 ImageNet 的。
按照 Capsules 的假设，在当前方案下，训练 ImageNet，估计至少要用长度100的向量来表征一个物体吧（可能还是不够）。假设我们卷积层保持 256 * 256 的长宽，256个独立的 Capsules 分组，那么一层就有 16777216 个 Capsules，我们不管其他的，就看最后输出1000个分类，需要1000个Capsules（假设向量长度还是100个元素），那么参数占用内存（设类型为float32）就是 16777216 * 1000 * （100*100*4）= 671088640000000 = 671.08864 TB（不计路由等部分）。实际训练中内存还会数倍于这个数字，至少要翻一倍，到1.7 PB左右。如果你要单独用GPU放下这一层，就需要 80000 张 Titan X Pascal，更别提整个网络的参数量。如此多的参数显然是因为全连接的动态路由造成的。相信路由方案一定是将来改进的重点。

本文出处：https://www.zhihu.com/question/67287444/answer/251241736

此图源自：https://zhuanlan.zhihu.com/p/30970675 

![1565868106188](D:\Notes\raw_images\1565868106188.png)