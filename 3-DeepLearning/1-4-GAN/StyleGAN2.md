## Analyzing and Improving the Image Quality of StyleGAN

论文地址：https://arxiv.org/abs/1912.04958

作者：Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila

机构：NVIDIA

代码地址：https://github.com/NVlabs/stylegan2



### 摘要

The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven（数据驱动） unconditional (非条件的）generative image modeling （生成图像模型）. ==We expose and analyze several of its characteristic artifacts（伪影）, and propose changes in both model architecture and training methods to address them==. 

In particular, we ==redesign generator normalization==, ==revisit progressive growing==, and ==regularize the generator to encourage good conditioning in the mapping from latent vectors to images==. In addition to improving image quality, this ==path length regularizer== yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably detect if an image is generated by a particular network. 

We furthermore visualize how well the generator utilizes its output resolution, and ==identify a capacity problem==, motivating us to train larger models for additional quality improvements. 

Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived（感知到的） image quality.



### 介绍

很多人发现 StyleGAN 生成的图像会有很有特点的伪影。这篇论文给出了产生这些伪影的两个原因，并描述了可以如何通过修改架构和训练方法来消除这些伪影。

首先，我们调研了 blob-like artifacts 的原由，生成器制造了它们来规避架构中的一个设计缺陷——我们重新设计了生成器中的 normalization 来移除这种伪影。

其次，我们分析了解到，artifacts 还和 progressive growing 有关系，我们用新的方法代替了 progressive growing， 训练开始于低分辨率图像, 然后逐渐转移专注到更高的分辨率——而不是在训练过程中改变网络的拓扑结构。

This new design also allows us to reason about the effective resolution of the generated images,
which turns out to be lower than expected, ==motivating a capacity increase== (Section 4).

FID 和 P&R 都是基于分类网络的评测方法，最近被证明更注重于纹理而不是shapes, 因而这些metrics并不能全面地评估图像的质量。 我们观察到 ==perceptual path length (PPL)== metric [24], introduced as a method for estimating the quality of latent space interpolations, correlates with consistency and stability of shapes.

在此基础上，我们将合成网络正则化，以支持平滑映射(第3节)，并获得明显的质量改进。为了抵消它的计算开销，我们还建议减少执行所有正则化的频率，我们注意到这样做不会影响效率。



### Normalization Artifacts

![1580716551850](D:\Notes\raw_images\1580716551850.png)

Figure 1. Instance normalization causes ==water droplet -like artifacts== in StyleGAN images. 

这个问题不是只在最后生成的图像上才有，而是在生成的过程中每一层都有，从64*64像素开始。这是一个系统问题污染所有StyleGAN生成的图片。 我们把问题定位到AdaIN操作上, AdaIN分别将每个特征图的均值和方差进行标准化, thereby potentially destroying any information found in the magnitudes（梯度） of the features relative to each other. 

这个假设作者是通过实验证明的，作者去掉AdaIN层后，这种水滴似的伪影就消失了。

![1580781267293](D:\Notes\raw_images\1580781267293.png)

(a) 原始的StyleGAN, 其中A表示从W中学习仿射变换产生一种样式，B表示噪声broadcast操作。

(b) 同样的结构，将AdaIN分解为显式的归一化（normalization）,然后是调制（modulation）,它们都是在每个特征映射的均值和标准偏差上运行的。我们还介绍了学习权重(w)、偏差(b)和常数输入(c),并重新绘制灰色框 - 表示一种活跃的样式。增加偏差后总是应用激活函数(leaky ReLU)。

修改：

有趣的是,==最初的StyleGAN是在样式块内施加偏差和噪声,导致它们相对的影响与当前样式的大小成反比==。我们观察到,通过将这些操作移动到样式块之外,从而获得更可预测的结果,在此块中,它们在规范化数据上运行。此外,我们注意到,在此之后,==规范化和调制足以操作标准偏差 (即mean操作是不需要的）==。==对恒定输入的偏差、噪声和归一化的应用也可以安全地删除,没有明显的缺点==。![1580780463418](D:\Notes\raw_images\1580780463418.png)

(c) 我们对原始架构进行了一些更改。在开始时,我们删除了一些多余的操作, 将b和B的添加移动到样式活动区域之外，并只调整每个特征映射的标准偏差。

(d)修订后的架构使用“demodulation”操作代替Instance Normalization操作，应用在卷积层的权重上。

![1580782131325](D:\Notes\raw_images\1580782131325.png)

![1580782095764](D:\Notes\raw_images\1580782095764.png)



### Path Length Regularization

perceptual path length (PPL) , a metric that was originally introduced for quantifying the smoothness of the mapping from a latent space to the output image by measuring average LPIPS distances [49] between generated images under small perturbations（扰乱） in latent space. 

**Lazy Regularization**

作者认为Regularization操作可以不需要和Loss计算这样频繁，采用每十次Loss计算一次Regularization的方式，发现实验效果并没有降低，下表中反而效果稍稍提升。

（作者做这个实验主要是基于PPL可以更好地表达生成图像的质量，但PPL的计算成本很好，作者想减少这方面的计算次数，以达到不错的效率）

![1580833604026](D:\Notes\raw_images\1580833604026.png)

**Path Length Regularization** 

![1580833413723](D:\Notes\raw_images\1580833413723.png)

It should be noted that spectral normalization [31] of the generator [45] only constrains the largest singular value, posing no constraints on the others and hence not necessarily leading to better conditioning. 

![1580833507001](D:\Notes\raw_images\1580833507001.png)

Figure 5. (a) Distribution of PPL scores of individual images generated using a baseline StyleGAN (config A in Table 1, FID = 8.53,PPL = 924). The percentile ranges corresponding to Figure 4 are highlighted in orange. 

(b) Our method (config F) improves the PPL distribution considerably (showing a snapshot with the same
FID = 8.53, PPL = 387).



### Progressive growing revisited

逐步增长[23]在稳定高分辨率图像合成方面取得了非常成功,但它导致了它自己的特征伪影。关键问题是,逐渐增长的生成器似乎对细节有着很强的==位置偏好==; 视频显示像牙齿或眼睛这样的特征应该在图像上流畅地移动时,它们可能会被固定在位置上。

![1580834276831](D:\Notes\raw_images\1580834276831.png)

图6，逐步增长导致“阶段”character artifacts 。在这个例子中,牙齿不遵循姿势改变, 而是与镜头保持一致,正如蓝色的线条所指示的那样。

作者认为这是网络结构逐步增长导致的，所以参考了多种网络结构：输入输出Skip，ResidualNet，修改网络结：

![1580834900963](D:\Notes\raw_images\1580834900963.png)

Figure 7. Three generator (above the dashed line) and discriminator architectures. Up and Down denote bilinear up and downsampling, respectively. In residual networks these also include 1x1 convolutions to adjust the number of feature maps. tRGB and fRGB convert between RGB and high-dimensional per-pixel
data. Architectures used in configurations E and F are highlighted in green.

三种结构实验结果如下：

![1580835483139](D:\Notes\raw_images\1580835483139.png)

我们可以看到两个广泛的趋势:在生成器中跳过连接在所有配置中大大提高了PPL。 一个残差的鉴别器网络显然对FID有益。由于鉴别器的结构类似分类器的结构, 因此并不令人惊讶。然而,在LSUN汽车中, 当两个网络都是残差结构的时候， ==生成器中使用残差结构是有害的==。

![1580834605185](D:\Notes\raw_images\1580834605185.png)

Figure 16. Progressive growing leads to significantly higher frequency content in the intermediate layers. This compromises shift invariance of the network and makes it harder to localize features precisely in the higher-resolution layers.

作者查看每一层对最后生成的图片的影响作分析，得出capacity problem

### Capacity Problem

![1580836185438](D:\Notes\raw_images\1580836185438.png)

图8。每层分辨率在训练时对生成器输出的贡献。垂直轴显示不同分辨率的相对标准差的分解, 水平轴对应于训练的进展。

我们可以看到,在开始的时候,网络专注于低分辨率的图像,并在训练过程中逐步将重点放在更大的分辨率上。在(a)中, 生成器基本上输出一个512 ^ 2的图像, 其中有一个小的锐化1024 ^ 2, 在(b)中更大的网络更多地关注高分辨率的细节。

解决方法：作者增加了高分辨率层网络Filter的个数，生成网络和鉴别网络都增加。

**其他操作：**

First, we add ramped-down（斜降；缓降） noise to the latent code during optimization in order to explore the latent space more comprehensively. 

Second, we also optimize the stochastic noise inputs of the StyleGAN generator, regularizing them to ensure they do not end up carrying coherent（耦合的） signal. The regularization is based on enforcing the auto correlation coefficients of the noise maps to match those of unit Gaussian noise over multiple scales. 



### 实验结果

![1580832018385](D:\Notes\raw_images\1580832018385.png)

Table 1. Main results. For each training run, we selected the training snapshot with the lowest FID. We computed each metric 10 times with different random seeds and report their average. 

The “path length” column corresponds to the PPL metric, computed based on path endpoints in W [24].

For LSUN datasets, we report path lengths without the center crop that was originally proposed for FFHQ. The FFHQ dataset contains 70k images, and we showed the discriminator 25M images during training. For LSUN CAR the corresponding numbers were 893k and 57M.

**实验效率：**

Training performance has also improved. At 1024^2 resolution, the original StyleGAN (config A in Table 1) trains at ==37 images per second on NVIDIA DGX-1 with 8 Tesla V100 GPUs==, while our config E trains 40% faster at 61img/s. Most of the speedup comes from simplified dataflow due to weight demodulation, lazy regularization, and code optimizations. 

Config F (larger networks) trains at 31 img/s, and is thus only slightly more expensive to train than original
StyleGAN. ==With config F, the total training time was 9 days for FFHQ and 13 days for LSUN CAR==.