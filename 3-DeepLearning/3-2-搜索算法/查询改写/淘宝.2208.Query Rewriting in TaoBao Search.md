## Query Rewriting in TaoBao Search

论文地址:  https://www.researchgate.net/publication/362546141

机构: 阿里巴巴，淘宝

作者：Sen Li, Jin Taiwei, Tao Zhuang, Qianli Ma

https://www.researchgate.net/profile/Sen-Li-38

https://www.researchgate.net/profile/Jin-Taiwei

https://www.researchgate.net/profile/Tao-Zhuang-4

https://www.researchgate.net/profile/Qianli-Ma-19



### 摘要

在电子商务搜索引擎中，查询重写 (QR) 的主旨是减少用户查询语句和产品目录描述之间的差距，是改善购物体验的关键技术。最近的工作方向主要是采用了生成范式。但是，它们几乎不能确保生成的重写语句的质量，并且没有个性化考虑，这会导致搜索相关性下降。

在这项工作中，我们提出了对比学习增强查询重写 (Contrastive Learning Enhanced Query Rewriting，CLE-QR)，这是淘宝产品搜索中使用的解决方案。它使用基于 “查询检索-语义相关性排名-在线排名” （“query retrieval−semantic relevance ranking−online ranking”）的新型对比学习增强架构。它从数亿个历史查询中找到重写的语句，同时考虑相关性和个性化。

> 具体来说，我们首先通过使用==无监督对比损失==（unsupervised contrastive loss）来缓解==查询检索阶段的表示退化问题==（ representation degeneration problem ），然后进一步提出==一种交互感知的匹配方法==来找到有益的增量的候选项，从而提高候选查询的质量和相关性。
>
> 我们然后在嘈杂的用户反馈数据上提出==一种面向相关性的对比预训练范式==，以提高语义排名性能。
>
> 最后，我们使用 user profile 对这些候选项进行在线排序，进行个性化建模，检索更多相关产品。

我们在中国最大的电子商务平台之一淘宝产品搜索上评估 CLE-QR。在在线 A/B 测试中观察到==显著的指标增益==。自2021年12月起，CLE-QR已部署到我们的大型商业检索系统，服务了数亿用户。我们还介绍了其在线部署方案，并分享了我们词汇匹配系统的实践经验和优化技巧。



### 介绍

<img src="D:\Notes\raw_images\image-20220926142546393.png" alt="image-20220926142546393" style="zoom:80%;" />

最近的方法 [17, 22, 29, 47] 通常采用基于embedding的学习范式，其中通过首先将用户、查询和产品embedding向量空间来获得用户-产品偏好预测。然而，==这种embedding会极大地损害搜索相关性，并导致大多数在线无法修复的bad cases [22, 31]。相反，查询重写 (QR) [40, 42] 更易于控制和解释。如图 1 所示，QR 将模棱两可的查询转换为表达更好的查询==。

> [17] Jui-Ting Huang, Ashish Sharma, Shuying Sun, Li Xia, David Zhang, Philip Pronin, Janani Padmanabhan, Giuseppe Ottaviano, and Linjun Yang. 2020. Embeddingbased retrieval in facebook search. In 26th SIGKDD. 2553–2561. （Facebook搜索）
>
> [22] Sen Li, Fuyu Lv, Taiwei Jin, Guli Lin, Keping Yang, Xiaoyi Zeng, Xiao-Ming Wu, and Qianli Ma. 2021. Embedding-Based Product Retrieval in Taobao Search. In 27th SIGKDD. 3181–3189. （淘宝搜索）
>
> [29] Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. Semantic product search. In 25th SIGKDD. 2876–2885.
>
> [47] Han Zhang, Songlin Wang, Kang Zhang, Zhiling Tang, Yunjiang Jiang, Yun Xiao, Weipeng Yan, and Wen-Yun Yang. 2020. Towards Personalized and Semantic Retrieval: An End-to-End Solution for E-commerce Search via Embedding Learning. In 43rd SIGIR. 2407–2416. （京东搜索）
>
> [31] Yiming Qiu, Kang Zhang, Han Zhang, Songlin Wang, Sulong Xu, Yun Xiao, Bo Long, and Wen-Yun Yang. 2021. Query Rewriting via Cycle-Consistent Translation for E-Commerce Search. In 37th ICDE. IEEE, 2435–2446. （京东搜索）

> [40] Yaxuan Wang, Hanqing Lu, Yunwen Xu, Rahul Goutam, Yiwei Song, and Bing Yin. 2021. QUEEN: Neural Query Rewriting in E-commerce. (2021). 
>
> [42] Rong Xiao, Jianhui Ji, Baoliang Cui, Haihong Tang, Wenwu Ou, Yanghua Xiao, Jiwei Tan, and Xuan Ju. 2019. Weakly Supervised Co-Training of Query Rewriting and Semantic Matching for e-Commerce. In 12th WSDM. 402–410

在产品搜索中，通过使用用户点击日志的语料库，京东 [31] 改进了他们 thesaurus-based baseline 基于词库的基线，该基线可能会遭受查询==意图漂移== [2, 18] 的影响。根据经验, ==执行生成重写比从用户搜索日志中挖掘历史重写更难 [7] 并且降低了搜索相关性==。因此，在本文中，对于给定的查询，我们旨在从数亿个搜索的历史查询中找到最相关的查询。

为了可扩展性和灵活性，所提出的查询重写系统采用两阶段架构（“query retrieval-semantic relevance ranking”）。

- 首先，通过两种方法检索相关的候选查询：（i）对上下文感知（context2vec）和内容感知（content2vec）Embedding [15]的近似最近邻（ANN）搜索，以及（ii）协同过滤。
- 然后，对于语义相关性排名（semantic relevance ranking），我们微调了 StructBERT [39]，它使用大规模电子商务领域数据进行了预训练，再用规模小但精度高的人工标注数据做 finetune。它根据统一的分数对各种方法生成的候选重写进行排名。

然而，与 word2vec 类似，content2vec 存在==查询表示退化问题== [13]，并且可能会降低候选查询的质量和相关性。此外，StructBERT 的预训练任务与我们微调的相关性排序==任务之间的差异==限制了相关性排序的性能。

> [39] Wei Wang, Bin Bi, Ming Yan, Chen Wu, Jiangnan Xia, Zuyi Bao, Liwei Peng, and Luo Si. 2020. StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding. In ICLR.
>
> [13] Jun Gao, Di He, Xu Tan, Tao Qin, Liwei Wang, and Tieyan Liu. 2019. Representation Degeneration Problem in Training Natural Language Generation Models. In ICLR.

- 为了解决上述问题，我们没有在查询检索中使用 content2vec，而是使用 StructBERT 初始化 Sentence-BERT (SBERT) [32]，并使用无监督对比损失对其进行训练，使查询表示分布更均匀。这可以防止表示崩溃，从而缓解表示退化问题。
- 此外，我们收集 (𝑞𝑢𝑒𝑟𝑦, 𝑟𝑒𝑤𝑞) 对（其中 rewq 代表重写查询），其中点击的产品仅由用户搜索日志中的重写查询 rewq 检索。然后，我们通过将这些对作为正例，将examples作为负例来训练具有对比损失的交互感知 SBERT。
- 对于语义排名，我们对嘈杂的用户反馈数据执行面向相关的预训练，并以对比目标弥合预训练和微调任务之间的差距。
- 最后，我们使用在线排名模块来进行个性化查询重写，以检索更多相关产品。

<img src="D:\Notes\raw_images\image-20220929115655699.png" alt="image-20220929115655699" style="zoom:80%;" />



