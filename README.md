# Categories

1. DataClean
2. Classification
3. Detection
4. OCR
5. GAN

# TODO List

## Face Recognition
论文：GhostVLAD for set-based face recognition
地址：https://arxiv.org/abs/1810.09951
阅读：https://mp.weixin.qq.com/s/R1hdkPTdFCo7JvOKNcEzJg 

## Data Clean 
论文：Few-Example Object Detection with Model Communication
地址：https://arxiv.org/pdf/1706.08249.pdf
论文：Towards Human-Machine Cooperation: Self-supervised Sample Mining for Object Detection
地址：http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3145.pdf

## RNN 
0 - The Unreasonable Effectiveness of Recurrent Neural Networks
The fall of RNN / LSTM
https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0

The Unreasonable Effectiveness of Recurrent Neural Networks
http://karpathy.github.io/2015/05/21/rnn-effectiveness/

Attention and Augmented Recurrent Neural Network
https://distill.pub/2016/augmented-rnns/
https://github.com/kjw0612/awesome-rnn

RNN Blog:
http://karpathy.github.io/2015/05/21/rnn-effectiveness/ 

RNN computation. So how do these things work? At the core, RNNs have a deceptively simple API: They accept an input vector x and give you an output vector y. However, crucially this output vector’s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you’ve fed in in the past. Written as a class, the RNN’s API consists of a single step function:

博客地址： https://gist.github.com/karpathy/d4dee566867f8291f086 

RNN: 其他博客教程
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/
https://zhuanlan.zhihu.com/p/22930328
http://www.deeplearning.net/tutorial/rnnslu.html#rnnslu
http://www.deeplearning.net/tutorial/lstm.html#lstm

LSTM介绍：
http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 

World2Vec 介绍：
Google 地址：https://code.google.com/archive/p/word2vec/

论文：Sequence to Sequence Learning with Neural Networks
论文地址：https://arxiv.org/pdf/1409.3215.pdf

An Intuitive Explanation of Connectionist Temporal Classification
CRNN
论文：An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition
论文地址：https://arxiv.org/abs/1507.05717

CTC 
论文：Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks
论文地址：http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.6306&rep=rep1&type=pdf
作者：Alex Graves

论文：SEE: Towards Semi-Supervised End-to-End Scene Text Recognition
论文地址：https://arxiv.org/pdf/1712.05404.pdf 
代码：https://github.com/Bartzi/see 

论文：Sequence to Sequence Learning for Optical Character Recognition
论文地址：https://arxiv.org/abs/1511.04176

### Detection
作者：Abhinav Shrivastava, Abhinav Gupta, Ross Girshick
Training Region-based Object Detectors with Online Hard Example Mining
论文： https://arxiv.org/abs/1604.03540

论文：Path Aggregation Network for Instance Segmentation
论文地址：https://arxiv.org/abs/1803.01534

SSD
论文：https://arxiv.org/abs/1512.02325
mxnet源码：
https://github.com/zhreshold/mxnet-ssd 
https://github.com/dmlc/mxnet/tree/master/example/ssd

YOLOV3
博客：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/
代码：https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch
论文：https://arxiv.org/abs/1804.02767

## softmax loss and the variants

## 初始化 - Xavier - MSRA


